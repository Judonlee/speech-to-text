{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__=\"Emily Hua\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to create some text files that will allow Kaldi to communicate with your audio data. Consider these files as 'must be done'. Each file that you will create in this section (and in Language data section as well) can be considered as a text file with some number of strings (each string in a new line). These strings need to be sorted. If you will encounter any sorting issues you can use Kaldi scripts for checking (utils/validate_data_dir.sh) and fixing (utils/fix_data_dir.sh) data order. And for you information - utils directory will be attached to your project in Tools attachment section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/STARTRACK/deep-learning/code-switch/speech-to-text\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "parent_path = os.path.split(os.getcwd())[0]\n",
    "print (parent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In kaldi/egs/code-switch directory, create a folder **data**. Then create **test** and **train** subfolders inside. Create in each subfolder following files (so you have files named in the same way in test and train subfolders but they relate to two different data sets that you created before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/train\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/test\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  2 yehua  staff  68 Mar 27 12:25 \u001b[1m\u001b[36mtest\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  2 yehua  staff  68 Mar 27 12:25 \u001b[1m\u001b[36mtrain\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls -l ../data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls -l ../data/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.) spk2gender \n",
    "This file informs about speakers gender. As we assumed, 'speakerID' is a unique name of each speaker.\n",
    "\n",
    "Pattern: [speakerID] [gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 95 unique speaker id\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "audio_path = parent_path + '/LDC2015S04/seame_d2/data/interview/audio'\n",
    "dir_list = os.listdir(audio_path)[1:]\n",
    "import re\n",
    "from collections import defaultdict \n",
    "id_dic = defaultdict(int)\n",
    "for file in dir_list:\n",
    "    id_dic[re.split('_', file)[0]] += 1\n",
    "print ('there are {} unique speaker id'.format(len(id_dic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 85 speaker ids in the training set\n",
      "there are 10 speaker ids in the testing set\n"
     ]
    }
   ],
   "source": [
    "test_short_ids = ['01MA', '03FA','08MA', '29FA','29MB','42FB','44MB','45FB','67MB','55FB']\n",
    "train_ids = []\n",
    "test_ids = []\n",
    "for key in id_dic:\n",
    "    short_speaker_id = key[2:-1]\n",
    "    if short_speaker_id not in test_short_ids:\n",
    "        train_ids.append(key)\n",
    "    else:\n",
    "        test_ids.append(key)\n",
    "print ('there are {} speaker ids in the training set'.format(len(train_ids)))\n",
    "print ('there are {} speaker ids in the testing set'.format(len(test_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NI42FBQ', 'NI45FBP', 'NI29MBP', 'NI55FBP', 'UI03FAZ']\n",
      "['UI16MAZ', 'NI22FBP', 'NI39FBP', 'UI15FAZ', 'NI46FBQ']\n"
     ]
    }
   ],
   "source": [
    "print (test_ids[:5])\n",
    "print (train_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/train/spk2gender\"\n",
    "with open(directory, 'w') as outfile:\n",
    "    for speakerid in train_ids:\n",
    "        outfile.write(\"{} {}\\n\".format(speakerid,speakerid[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/test/spk2gender\"\n",
    "with open(directory, 'w') as outfile:\n",
    "    for speakerid in test_ids:\n",
    "        outfile.write(\"{} {}\\n\".format(speakerid, speakerid[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/test/spk2gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/train/spk2gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.) wav.scp \n",
    "This file connects every utterance (sentence said by one person during particular recording session) with an audio file related to this utterance. If you stick to my naming approach, 'utteranceID' is nothing more than 'speakerID' (speaker's folder name) glued with *.wav file name without '.wav' ending (look for examples below).\n",
    "\n",
    "Pattern: [recordingID] [full_path_to_audio_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 93848\r\n",
      "-rw-r--r--  1 yehua  staff  48047643 Mar 27 12:14 NI01MAX_0101.flac\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../interview_audio/test/01MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/train/wav.scp\"\n",
    "with open(directory, 'w') as outfile:\n",
    "    for file in dir_list:\n",
    "        speaker_id = re.split(\"_\", file)[0]\n",
    "        if speaker_id in train_ids:\n",
    "            path = parent_path + \"/interview_audio/train/\" + speaker_id + \"/\" + file\n",
    "            outfile.write(\"{} flac -c -d -s {} |\\n\".format(re.split(\"\\.\", file)[0], path))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/test/wav.scp\"\n",
    "with open(directory, 'w') as outfile:\n",
    "    for file in dir_list:\n",
    "        speaker_id = re.split(\"_\", file)[0]\n",
    "        if speaker_id in test_ids:\n",
    "            path = parent_path + \"/interview_audio/test/\" + speaker_id + \"/\" + file\n",
    "            outfile.write(\"{} flac -c -d -s {} |\\n\".format(re.split(\"\\.\", file)[0], path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/test/wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/train/wav.scp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.) text \n",
    "This file contains every utterance matched with its text transcription.\n",
    "\n",
    "Pattern: [uterranceID] [text_transcription]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans_path = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript\"\n",
    "trans_list = os.listdir(trans_path)[1:]\n",
    "directory = parent_path + \"/data/train/text\"\n",
    "with open(directory, 'w') as outputfile:\n",
    "    for file in trans_list: \n",
    "        speaker_id = re.split(\"_\", file)[0]\n",
    "        if speaker_id in train_ids:\n",
    "            trans_file = trans_path + \"/\" + file\n",
    "            with open(trans_file, 'r') as inputfile:\n",
    "                for line in inputfile:\n",
    "                    text = re.split(\"\\t\", line)[-1]\n",
    "                    prefix = re.split(\"\\t\", line)[0]\n",
    "                    first_frame = re.split(\"\\t\", line)[1].zfill(7)\n",
    "                    second_frame = re.split(\"\\t\", line)[2].zfill(7)\n",
    "                    utterance_id = prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "                    outputfile.write(\"{} {}\".format(utterance_id, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/train/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_path = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript\"\n",
    "trans_list = os.listdir(trans_path)[1:]\n",
    "directory = parent_path + \"/data/test/text\"\n",
    "with open(directory, 'w') as outputfile:\n",
    "    for file in trans_list: \n",
    "        speaker_id = re.split(\"_\", file)[0]\n",
    "        if speaker_id in test_ids:\n",
    "            trans_file = trans_path + \"/\" + file\n",
    "            with open(trans_file, 'r') as inputfile:\n",
    "                for line in inputfile:\n",
    "                    text = re.split(\"\\t\", line)[-1]\n",
    "                    prefix = re.split(\"\\t\", line)[0]\n",
    "                    first_frame = re.split(\"\\t\", line)[1].zfill(7)\n",
    "                    second_frame = re.split(\"\\t\", line)[2].zfill(7)\n",
    "                    utterance_id = prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "                    outputfile.write(\"{} {}\".format(utterance_id, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/test/text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.) utt2spk \n",
    "This file tells the ASR system which utterance belongs to particular speaker.\n",
    "\n",
    "Pattern: [uterranceID] [speakerID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 209 recording with transcript\n",
      "there are 210 recording in audio files\n",
      "match!\n",
      "largest_frame is 7004497\n",
      "since 7004497 is our largest frame, then we need to create string with 7 digits to hold all frames\n"
     ]
    }
   ],
   "source": [
    "trans_path = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript/\"\n",
    "import sys\n",
    "largest_frame = -sys.maxsize\n",
    "trans_list = os.listdir(trans_path)[1:]\n",
    "print (\"there are {} recording with transcript\".format(len(trans_list)))\n",
    "print (\"there are {} recording in audio files\".format(len(dir_list)))\n",
    "print (\"match!\")\n",
    "\n",
    "for file in trans_list:\n",
    "    file_path = trans_path + \"/\" + file\n",
    "    with open(file_path, 'r') as inputfile:\n",
    "        for line in inputfile:\n",
    "            second_frame = int(re.split(\"\\t\", line)[2])\n",
    "            if second_frame > largest_frame:\n",
    "                largest_frame = second_frame\n",
    "print (\"largest_frame is {}\".format(largest_frame))  \n",
    "print (\"since 7004497 is our largest frame, then we need to create string with 7 digits to hold all frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 40515 new utterance ids\n"
     ]
    }
   ],
   "source": [
    "# create utterance id: recording id + start time + end time; for e.g. NI01MAX_0101_0001353_0003612\n",
    "counter = 0\n",
    "utter_ids = []\n",
    "for file in trans_list:\n",
    "    file_path = trans_path + \"/\" + file\n",
    "    with open(file_path, 'r') as inputfile:\n",
    "        for line in inputfile:\n",
    "            speaker_id = re.split(\"_\", line)[0]\n",
    "            prefix = re.split(\"\\t\", line)[0]\n",
    "            first_frame = re.split(\"\\t\", line)[1].zfill(7)\n",
    "            second_frame = re.split(\"\\t\", line)[2].zfill(7)\n",
    "            utterance_id =  prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "            utter_ids.append(utterance_id)\n",
    "print (\"there are {} new utterance ids\".format(len(utter_ids)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample newly created utterance id ['NI02FAX_0101_0055711_0060021']\n"
     ]
    }
   ],
   "source": [
    "print(\"sample newly created utterance id {}\".format(utter_ids[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 37060 in train/utt2spk\n"
     ]
    }
   ],
   "source": [
    "utt2spk_path = parent_path + \"/data/train/utt2spk\"\n",
    "counter = 0\n",
    "with open(utt2spk_path, 'w') as outputfile:\n",
    "    for file in utter_ids:\n",
    "        speaker_id = re.split(\"_\", file)[0]\n",
    "        if speaker_id in train_ids:\n",
    "            counter += 1\n",
    "            outputfile.write(\"{} {}\\n\".format(re.split(\"\\.\", file)[0], speaker_id))\n",
    "print (\"there are {} in train/utt2spk\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3455 in test/utt2spk\n"
     ]
    }
   ],
   "source": [
    "utt2spk_path = parent_path + \"/data/test/utt2spk\"\n",
    "counter = 0\n",
    "with open(utt2spk_path, 'w') as outputfile:\n",
    "    for file in utter_ids:\n",
    "        speaker_id = re.split(\"_\", file)[0]\n",
    "        if speaker_id in test_ids:\n",
    "            counter += 1\n",
    "            outputfile.write(\"{} {}\\n\".format(re.split(\"\\.\", file)[0], speaker_id))\n",
    "print (\"there are {} in test/utt2spk\".format(counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/train/utt2spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/test/utt2spk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.) corpus.txt \n",
    "This file has a slightly different directory. In kaldi-trunk/egs/digits/data create another folder local. In kaldi/egs/code-switching/data/local create a file corpus.txt which should contain every single utterance transcription that can occur in your ASR system (in our case it will be 100 lines from 100 audio files).\n",
    "\n",
    "Pattern: [text_transcription]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_path = parent_path + \"/data/local\"\n",
    "if not os.path.exists(temp_path):\n",
    "    os.makedirs(temp_path)\n",
    "    \n",
    "corpus_path = parent_path + \"/data/local/corpus.txt\"\n",
    "trans_path = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript\"\n",
    "trans_list = os.listdir(trans_path)[1:]\n",
    "\n",
    "with open(corpus_path, 'w') as outputfile:\n",
    "    for file in trans_list: \n",
    "            trans_file = trans_path + \"/\" + file\n",
    "            with open(trans_file, 'r') as inputfile:\n",
    "                for line in inputfile:\n",
    "                    #outputfile.write(line)\n",
    "                    outputfile.write(re.split(\"\\t\", line)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/local/corpus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
