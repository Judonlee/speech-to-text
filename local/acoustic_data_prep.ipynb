{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__=\"Emily Hua\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to create some text files that will allow Kaldi to communicate with your audio data. Consider these files as 'must be done'. Each file that you will create in this section (and in Language data section as well) can be considered as a text file with some number of strings (each string in a new line). These strings need to be sorted. If you will encounter any sorting issues you can use Kaldi scripts for checking (utils/validate_data_dir.sh) and fixing (utils/fix_data_dir.sh) data order. And for you information - utils directory will be attached to your project in Tools attachment section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/STARTRACK/deep-learning/code-switch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "parent_path = os.path.split(os.getcwd())[0]\n",
    "print (parent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In kaldi/egs/code-switch directory, create a folder **data**. Then create **test** and **train** subfolders inside. Create in each subfolder following files (so you have files named in the same way in test and train subfolders but they relate to two different data sets that you created before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/train\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/test\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 24 15:11 \u001b[1m\u001b[36mtest\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 24 15:03 \u001b[1m\u001b[36mtrain\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.) spk2gender \n",
    "This file informs about speakers gender. As we assumed, 'speakerID' is a unique name of each speaker.\n",
    "\n",
    "Pattern: [speakerID] [gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 94 unique speaker id\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "audio_path = parent_path + '/LDC2015S04/seame_d2/data/interview/audio'\n",
    "dir_list = os.listdir(audio_path)[1:]\n",
    "import re\n",
    "from collections import defaultdict \n",
    "id_dic = defaultdict(int)\n",
    "for file in dir_list:\n",
    "    id_dic[re.split('_', file)[0][2:-1]] += 1\n",
    "print ('there are {} unique speaker id'.format(len(id_dic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 84 speaker ids in the training set\n"
     ]
    }
   ],
   "source": [
    "test_ids = ['01MA', '03FA','08MA', '29FA','29MB','42FB','44MB','45FB','67MB','55FB']\n",
    "train_ids = []\n",
    "for key in id_dic:\n",
    "    if key not in test_ids:\n",
    "        train_ids.append(key)\n",
    "print ('there are {} speaker ids in the training set'.format(len(train_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/train/spk2gender\"\n",
    "with open(directory, 'w') as outfile:\n",
    "    for speakerid in train_ids:\n",
    "        outfile.write(\"{} {}\\n\".format(speakerid,speakerid[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/test/spk2gender\"\n",
    "with open(directory, 'w') as outfile:\n",
    "    for speakerid in test_ids:\n",
    "        outfile.write(\"{} {}\\n\".format(speakerid, speakerid[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/test/spk2gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.) wav.scp \n",
    "This file connects every utterance (sentence said by one person during particular recording session) with an audio file related to this utterance. If you stick to my naming approach, 'utteranceID' is nothing more than 'speakerID' (speaker's folder name) glued with *.wav file name without '.wav' ending (look for examples below).\n",
    "\n",
    "Pattern: [uterranceID] [full_path_to_audio_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 93848\r\n",
      "-rw-r--r--  1 yehua  staff  48047643 Mar 24 12:35 NI01MAX_0101.flac\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../interview_audio/test/01MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/train/wav.scp\"\n",
    "with open(directory, 'w') as outfile:\n",
    "    for file in dir_list:\n",
    "        speaker_id = re.split(\"_\", file)[0][2:-1]\n",
    "        if speaker_id in train_ids:\n",
    "            path = parent_path + \"/interview_audio/train\" + speaker_id + \"/\" + file\n",
    "            outfile.write(\"{} {}\\n\".format(re.split(\"\\.\", file)[0], path))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path + \"/data/test/wav.scp\"\n",
    "with open(directory, 'w') as outfile:\n",
    "    for file in dir_list:\n",
    "        speaker_id = re.split(\"_\", file)[0][2:-1]\n",
    "        if speaker_id in test_ids:\n",
    "            path = parent_path + \"/interview_audio/test\" + speaker_id + \"/\" + file\n",
    "            outfile.write(\"{} {}\\n\".format(re.split(\"\\.\", file)[0], path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/test/wav.scp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.) text \n",
    "This file contains every utterance matched with its text transcription.\n",
    "\n",
    "Pattern: [uterranceID] [text_transcription]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans_path = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript\"\n",
    "trans_list = os.listdir(trans_path)[1:]\n",
    "directory = parent_path + \"/data/train/text\"\n",
    "with open(directory, 'w') as outputfile:\n",
    "    for file in trans_list: \n",
    "        speaker_id = re.split(\"_\", file)[0][2:-1]\n",
    "        if speaker_id in train_ids:\n",
    "            trans_file = trans_path + \"/\" + file\n",
    "            with open(trans_file, 'r') as inputfile:\n",
    "                for line in inputfile:\n",
    "                    outputfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/train/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_path = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript\"\n",
    "trans_list = os.listdir(trans_path)[1:]\n",
    "directory = parent_path + \"/data/test/text\"\n",
    "with open(directory, 'w') as outputfile:\n",
    "    for file in trans_list: \n",
    "        speaker_id = re.split(\"_\", file)[0][2:-1]\n",
    "        if speaker_id in test_ids:\n",
    "            trans_file = trans_path + \"/\" + file\n",
    "            with open(trans_file, 'r') as inputfile:\n",
    "                for line in inputfile:\n",
    "                    outputfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/test/text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.) utt2spk \n",
    "This file tells the ASR system which utterance belongs to particular speaker.\n",
    "\n",
    "Pattern: [uterranceID] [speakerID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utt2spk_path = parent_path + \"/data/train/utt2spk\"\n",
    "with open(utt2spk_path, 'w') as outputfile:\n",
    "    for file in dir_list:\n",
    "        speaker_id = re.split(\"_\", file)[0][2:-1]\n",
    "        if speaker_id in train_ids:\n",
    "            outputfile.write(\"{} {}\\n\".format(re.split(\"\\.\", file)[0], speaker_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utt2spk_path = parent_path + \"/data/test/utt2spk\"\n",
    "with open(utt2spk_path, 'w') as outputfile:\n",
    "    for file in dir_list:\n",
    "        speaker_id = re.split(\"_\", file)[0][2:-1]\n",
    "        if speaker_id in test_ids:\n",
    "            outputfile.write(\"{} {}\\n\".format(re.split(\"\\.\", file)[0], speaker_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/train/utt2spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/test/utt2spk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.) corpus.txt \n",
    "This file has a slightly different directory. In kaldi-trunk/egs/digits/data create another folder local. In kaldi/egs/code-switching/data/local create a file corpus.txt which should contain every single utterance transcription that can occur in your ASR system (in our case it will be 100 lines from 100 audio files).\n",
    "\n",
    "Pattern: [text_transcription]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_path = parent_path + \"/data/local\"\n",
    "if not os.path.exists(temp_path):\n",
    "    os.makedirs(temp_path)\n",
    "    \n",
    "corpus_path = parent_path + \"/data/local/corpus.txt\"\n",
    "trans_path = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript\"\n",
    "trans_list = os.listdir(trans_path)[1:]\n",
    "\n",
    "with open(corpus_path, 'w') as outputfile:\n",
    "    for file in trans_list: \n",
    "            trans_file = trans_path + \"/\" + file\n",
    "            with open(trans_file, 'r') as inputfile:\n",
    "                for line in inputfile:\n",
    "                    #outputfile.write(line)\n",
    "                    outputfile.write(re.split(\"\\t\", line)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/local/corpus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
