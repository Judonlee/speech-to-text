{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__=\"Emily Hua\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to kaldi/egs/code-switch directory and create itnerview_audio folder. In kaldi-trunk/egs/code-switch/interview_audio create two folders: train and test. Select ten speaker of your choice to represent testing data set. Use this speaker's 'speakerID' as a name for an another new folder in kaldi-trunk/egs/code-switch/interview_audio/test directory. Then put there all the audio files related to that person. Put the rest (84 speakers) into train folder - this will be your training data set. Also create subfolders for each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8991184\r\n",
      "-rwxr-xr-x  1 yehua  staff  48047643 Feb 16 12:56 NI01MAX_0101.flac*\r\n",
      "-rwxr-xr-x  1 yehua  staff  50547368 Feb 16 12:56 NI02FAX_0101.flac*\r\n",
      "-rwxr-xr-x  1 yehua  staff  64271878 Feb 16 12:56 NI03FBX_0101.flac*\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../LDC2015S04/seame_d2/data/interview/audio | head -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/STARTRACK/deep-learning/code-switch/speech-to-text\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "parent_path = os.path.split(os.getcwd())[0]\n",
    "print (parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are total 209 of files in /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/LDC2015S04/seame_d2/data/interview/audio\n"
     ]
    }
   ],
   "source": [
    "audio_path = parent_path + '/LDC2015S04/seame_d2/data/interview/audio'\n",
    "dir_list = os.listdir(audio_path)[1:]\n",
    "print (\"there are total {} of files in {}\".format(len(dir_list), audio_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 94 unique prefix sets\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "#### create train and test set ###\n",
    "##################################\n",
    "import re\n",
    "from collections import defaultdict \n",
    "id_dic = defaultdict(int)\n",
    "for file in dir_list:\n",
    "    id_dic[re.split('_', file)[0][2:-1]] += 1\n",
    "print ('there are {} unique prefix sets'.format(len(id_dic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = ['01MA', '03FA','08MA', '29FA','29MB','42FB','44MB','45FB','67MB','55FB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 84 speaker ids in the training set\n"
     ]
    }
   ],
   "source": [
    "train_ids = []\n",
    "for key in id_dic:\n",
    "    if key not in test_ids:\n",
    "        train_ids.append(key)\n",
    "print ('there are {} speaker ids in the training set'.format(len(train_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22FB', '63MB', '12FA', '07FA', '09MA', '20MB', '13FA', '28FA', '13MB', '58FB', '64FB', '21MB', '65MB', '15FB', '16MA', '30MB', '36MB', '52MB', '19MB', '01FA', '62MB', '39FB', '22MA', '09FB', '27FA', '46FB', '33MB', '10FA', '04FA', '10FB', '48FB', '17FB', '66MB', '07FB', '05MB', '05MA', '06FB', '61FB', '26FB', '24MA', '40FB', '23FB', '28MB', '56MB', '51MB', '15FA', '26MA', '60MB', '49MB', '57FB', '18MA', '54FB', '21MA', '53FB', '08FB', '14MA', '23FA', '11FB', '18MB', '24MB', '25FA', '43FB', '32FB', '31FB', '25MB', '14MB', '11FA', '41MB', '37MB', '03FB', '06MA', '34FB', '27MB', '16FB', '17FA', '35FB', '20MA', '12MA', '04FB', '59FB', '02FA', '50FB', '47MB', '19MA']\n"
     ]
    }
   ],
   "source": [
    "print(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 16 files ready to be moved into the test set, should equal 16 by the way\n"
     ]
    }
   ],
   "source": [
    "test_wannabe = []\n",
    "for file in dir_list:\n",
    "    speaker_id = re.split('_', file)[0][2:-1]\n",
    "    if speaker_id in test_ids:\n",
    "        test_wannabe.append(file)\n",
    "        # I have add a file from this prefix into the test set, no need for more from this prefix\n",
    "print (\"there are {} files ready to be moved into the test set, should equal 16 by the way\".format(len(test_wannabe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/interview_audio\n"
     ]
    }
   ],
   "source": [
    "directory = parent_path + \"/interview_audio\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "print (directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls -l ../interview_audio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading audios into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/interview_audio/test\n",
      "loading finished\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "directory += \"/test\"\n",
    "print (\"loading audios into {}\".format(directory))\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    for file in test_wannabe:\n",
    "        speaker_id = re.split('_',file)[0][2:-1]\n",
    "        if not os.path.exists(directory + \"/\" + speaker_id):\n",
    "            os.makedirs(directory + \"/\" + speaker_id)\n",
    "        src = audio_path + \"/\" + file\n",
    "        dst = directory + \"/\" + speaker_id + \"/\" + file\n",
    "        copyfile(src, dst)\n",
    "print (\"loading finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 27 12:14 \u001b[1m\u001b[36m01MA\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 27 12:14 \u001b[1m\u001b[36m03FA\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  6 yehua  staff  204 Mar 27 12:14 \u001b[1m\u001b[36m08MA\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  6 yehua  staff  204 Mar 27 12:14 \u001b[1m\u001b[36m29FA\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 27 12:14 \u001b[1m\u001b[36m29MB\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 27 12:14 \u001b[1m\u001b[36m42FB\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 27 12:14 \u001b[1m\u001b[36m44MB\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 27 12:14 \u001b[1m\u001b[36m45FB\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 27 12:14 \u001b[1m\u001b[36m55FB\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 27 12:14 \u001b[1m\u001b[36m67MB\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../interview_audio/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading audios into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/interview_audio/train\n",
      "loading finished\n"
     ]
    }
   ],
   "source": [
    "# @train_ids stores speaker that is supposed to be in the train set\n",
    "from shutil import copyfile\n",
    "directory = parent_path + \"/interview_audio\"\n",
    "directory += \"/train\"\n",
    "print (\"loading audios into {}\".format(directory))\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    for file in dir_list:\n",
    "        speaker_id = re.split('_',file)[0][2:-1]\n",
    "        if speaker_id in train_ids:\n",
    "            if not os.path.exists(directory + \"/\" + speaker_id):\n",
    "                os.makedirs(directory + \"/\" + speaker_id)\n",
    "            src = audio_path + \"/\" + file\n",
    "            dst = directory + \"/\" + speaker_id + \"/\" + file\n",
    "            copyfile(src, dst)\n",
    "print (\"loading finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  10 yehua  staff  340 Mar 27 12:16 01FA/\r\n",
      "drwxr-xr-x   8 yehua  staff  272 Mar 27 12:16 02FA/\r\n",
      "drwxr-xr-x   3 yehua  staff  102 Mar 27 12:15 03FB/\r\n",
      "drwxr-xr-x   7 yehua  staff  238 Mar 27 12:16 04FA/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../interview_audio/train | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 135328\r\n",
      "-rw-r--r--  1 yehua  staff   8452113 Mar 27 12:16 UI01FAZ_0101.flac\r\n",
      "-rw-r--r--  1 yehua  staff   8655988 Mar 27 12:16 UI01FAZ_0102.flac\r\n",
      "-rw-r--r--  1 yehua  staff   8481489 Mar 27 12:16 UI01FAZ_0103.flac\r\n",
      "-rw-r--r--  1 yehua  staff   8316971 Mar 27 12:16 UI01FAZ_0104.flac\r\n",
      "-rw-r--r--  1 yehua  staff   8474677 Mar 27 12:16 UI01FAZ_0105.flac\r\n",
      "-rw-r--r--  1 yehua  staff   7864642 Mar 27 12:16 UI01FAZ_0106.flac\r\n",
      "-rw-r--r--  1 yehua  staff  10334179 Mar 27 12:16 UI01FAZ_0107.flac\r\n",
      "-rw-r--r--  1 yehua  staff   8687814 Mar 27 12:16 UI01FAZ_0108.flac\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../interview_audio/train/01FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
