{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__=\"Emily Hua\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to kaldi/egs/code-switch directory and create itnerview_audio folder. In kaldi-trunk/egs/code-switch/interview_audio create two folders: train and test. Select ten speaker of your choice to represent testing data set. Use this speaker's 'speakerID' as a name for an another new folder in kaldi-trunk/egs/code-switch/interview_audio/test directory. Then put there all the audio files related to that person. Put the rest (84 speakers) into train folder - this will be your training data set. Also create subfolders for each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8991184\r\n",
      "-rwxr-xr-x  1 yehua  staff  48047643 Feb 16 12:56 NI01MAX_0101.flac*\r\n",
      "-rwxr-xr-x  1 yehua  staff  50547368 Feb 16 12:56 NI02FAX_0101.flac*\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../LDC2015S04/seame_d2/data/interview/audio | head -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7925480\r\n",
      "-rwxr-xr-x  1 yehua  staff   95609160 Feb 16 12:51 01NC01FBX_0101.flac*\r\n",
      "-rwxr-xr-x  1 yehua  staff  123991309 Feb 16 12:51 01NC02FBY_0101.flac*\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../LDC2015S04/seame_d1/data/conversation/audio | head -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "parent_path = os.path.split(os.getcwd())[0]\n",
    "print (parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are total 210 of files in /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/LDC2015S04/seame_d2/data/interview/audio\n",
      "\n",
      "there are total 87 of files in /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/LDC2015S04/seame_d1/data/conversation/audio\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_files(audio_path):\n",
    "    dir_list = os.listdir(audio_path)[1:]\n",
    "    print (\"there are total {} of files in {}\\n\".format(len(dir_list), audio_path))\n",
    "    return dir_list\n",
    "audio_path_i = parent_path + '/LDC2015S04/seame_d2/data/interview/audio'\n",
    "audio_path_c = parent_path + '/LDC2015S04/seame_d1/data/conversation/audio'\n",
    "dir_list_i = count_files(audio_path_i)\n",
    "dir_list_c = count_files(audio_path_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 95 unique prefix sets\n",
      "there are 79 unique prefix sets\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict \n",
    "def speaker_re_counts(dir_list):\n",
    "    id_dic = defaultdict(int)\n",
    "    for file in dir_list:\n",
    "        id_dic[re.split('_', file)[0]] += 1\n",
    "    print ('there are {} unique prefix sets'.format(len(id_dic)))\n",
    "    return id_dic\n",
    "id_dic_i = speaker_re_counts(dir_list_i)\n",
    "id_dic_c = speaker_re_counts(dir_list_c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker ids and number of recordings they have: {'22NC44MBQ': 1, '08NC16FBQ': 1, '02NC03FBX': 2}\n"
     ]
    }
   ],
   "source": [
    "print (\"example speaker ids and number of recordings in converstaion they have: {}\".format(dict(list(id_dic_c.items())[:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example speaker ids and number of recordings in interview they have: {'NI58FBP': 1, 'UI11FAZ': 3, 'NI14MBP': 1}\n"
     ]
    }
   ],
   "source": [
    "print (\"example speaker ids and number of recordings in interview they have: {}\".format(dict(list(id_dic_i.items())[:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_short_ids_i = ['01MA', '03FA','08MA', '29FA','29MB','42FB','44MB','45FB','67MB','55FB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_short_ids_c = ['30NC48FB', '18NC36MB','43NC61FB', '34NC37MB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 85 speaker ids in the training set\n",
      "there are 10 speaker ids in the testing set\n",
      "\n",
      "there are 75 speaker ids in the training set\n",
      "there are 4 speaker ids in the testing set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(id_dic, test_short_ids):\n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "    for key in id_dic:\n",
    "        if key[2:-1] in test_short_ids or key[:-1] in test_short_ids:\n",
    "            test_ids.append(key)\n",
    "        else: \n",
    "            train_ids.append(key)\n",
    "    print ('there are {} speaker ids in the training set'.format(len(train_ids)))\n",
    "    print ('there are {} speaker ids in the testing set\\n'.format(len(test_ids)))\n",
    "    return train_ids, test_ids\n",
    "train_ids_i, test_ids_i = train_test_split(id_dic_i, test_short_ids_i)\n",
    "train_ids_c, test_ids_c = train_test_split(id_dic_c, test_short_ids_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 85 speaker ids in the training set\n",
    "there are 10 speaker ids in the testing set\n",
    "\n",
    "there are 75 speaker ids in the training set\n",
    "there are 4 speaker ids in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker ids in the converation test set: ['34NC37MBP', '43NC61FBQ', '18NC36MBQ', '30NC48FBP']\n",
      "\n",
      "speaker ids in the interview test set: ['NI44MBQ', 'NI29MBP', 'UI08MAZ', 'NI01MAX', 'UI03FAZ', 'NI42FBQ', 'NI67MBQ', 'NI45FBP', 'UI29FAZ', 'NI55FBP']\n"
     ]
    }
   ],
   "source": [
    "print (\"speaker ids in the converation test set: {}\\n\".format(test_ids_c))\n",
    "print (\"speaker ids in the interview test set: {}\".format(test_ids_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker ids in the conversation train set: \n",
      "['22NC44MBQ', '08NC16FBQ', '02NC03FBX', '37NC45MBP', '46NC41MBP', '21NC41MBP', '29NC53MBP', '33NC37MBP', '06NC11MAX', '20NC40FBQ', '14NC27MBP', '13NC25MBP', '17NC33FBP', '40NC58FAY', '04NC08FBY', '14NC28MBQ', '45NC22MBQ', '04NC07FBX', '32NC36MBQ', '42NC60FBQ', '28NC51MBP', '44NC44MBQ', '33NC43FBQ', '25NC47MBP', '10NC19MBP', '39NC57FBX', '21NC42MBQ', '15NC29FBP', '20NC39MBP', '29NC54FBQ', '12NC24FBQ', '27NC47MBQ', '11NC21FBP', '24NC35FBQ', '05NC10MAY', '01NC02FBY', '18NC35FBP', '15NC30MBQ', '03NC05FAX', '13NC26MBQ', '30NC49FBQ', '23NC35FBQ', '28NC52FBQ', '41NC59MAX', '08NC15MBP', '05NC09FAX', '07NC13MBP', '07NC14FBQ', '10NC20MBQ', '03NC06FAY', '26NC49FBQ', '16NC32FBQ', '32NC50FBP', '19NC38FBQ', '24NC45MBP', '17NC34FBQ', '26NC48FBP', '01NC01FBX', '11NC22MBQ', '19NC37MBP', '16NC31FBP', '31NC35FBQ', '38NC50FBP', '36NC46FBQ', '25NC43FBQ', '35NC56MBP', '06NC12MAY', '09NC18MBQ', '22NC43FBP', '27NC50FBP', '12NC23FBP', '23NC45MBP', '09NC17FBP', '02NC04FBY', '31NC50XFB']\n",
      "\n",
      "speaker ids in the interview train set: \n",
      "['UI11FAZ', 'NI14MBP', 'NI58FBP', 'NI61FBP', 'NI53FBP', 'UI28FAZ', 'UI13FAZ', 'UI22MAZ', 'NI22FBP', 'UI15FAZ', 'UI19MAZ', 'UI10FAZ', 'UI12FAZ', 'UI04FAZ', 'UI24MAZ', 'NI59FBQ', 'UI20MAZ', 'NI60MBP', 'NI57FBQ', 'NI02FAX', 'NI54FBQ', 'NI40FBQ', 'NI17FBQ', 'UI17FAZ', 'NI50FBQ', 'NI34FBQ', 'NI18MBP', 'NI46FBQ', 'UI09MAZ', 'NI33MBP', 'NI19MBQ', 'NI13MBQ', 'UI01FAZ', 'NI15FBQ', 'UI14MAZ', 'UI21MAZ', 'NI30MBQ', 'NI32FBQ', 'NI43FBP', 'NI10FBP', 'NI64FBQ', 'NI20MBP', 'NI16FBP', 'NI65MBP', 'NI26FBP', 'NI24MBP', 'NI63MBP', 'NI12MAP', 'NI36MBQ', 'UI16MAZ', 'NI62MBQ', 'NI66MBQ', 'NI23FBQ', 'NI27MBQ', 'NI35FBP', 'UI07FAZ', 'NI03FBX', 'UI26MAZ', 'UI23FAZ', 'NI48FBQ', 'UI18MAZ', 'NI52MBQ', 'NI08FBP', 'NI04FBX', 'NI39FBP', 'UI27FAZ', 'NI47MBP', 'NI05MBQ', 'NI28MBP', 'UI02FAZ', 'NI37MBP', 'NI11FBP', 'UI25FAZ', 'NI21MBQ', 'UI05MAZ', 'NI25MBQ', 'NI56MBX', 'NI49MBP', 'NI06FBP', 'NI07FBQ', 'NI31FBP', 'NI51MBP', 'UI06MAZ', 'NI41MBP', 'NI09FBP']\n"
     ]
    }
   ],
   "source": [
    "print (\"speaker ids in the conversation train set: \\n{}\\n\".format(train_ids_c))\n",
    "print (\"speaker ids in the interview train set: \\n{}\".format(train_ids_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 16 files ready to be moved into the test set\n",
      "there are 4 files ready to be moved into the test set\n"
     ]
    }
   ],
   "source": [
    "def create_test_wannabe(dir_list, test_ids):\n",
    "    test_wannabe = []\n",
    "    for file in dir_list:\n",
    "        speaker_id = re.split('_', file)[0]\n",
    "        if speaker_id in test_ids:\n",
    "            test_wannabe.append(file)\n",
    "            # I have add a file from this prefix into the test set, no need for more from this prefix\n",
    "    print (\"there are {} files ready to be moved into the test set\".format(len(test_wannabe)))    \n",
    "    return test_wannabe\n",
    "test_wannabe_i = create_test_wannabe(dir_list_i, test_ids_i)\n",
    "test_wannabe_c = create_test_wannabe(dir_list_c, test_ids_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be   \n",
    "there are 16 files ready to be moved into the test set  \n",
    "there are 4 files ready to be moved into the test set  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  12 yehua  staff  408 Mar 29 00:29 \u001b[1m\u001b[36mtest\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../interview_audio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/interview_audio\n",
      "loading interview recordings into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/interview_audio/test\n",
      "loading finished\n"
     ]
    }
   ],
   "source": [
    "# load interview recordings into the test set \n",
    "from shutil import copyfile\n",
    "directory = parent_path + \"/audio\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "print (directory)\n",
    "directory += \"/test\"\n",
    "print (\"loading interview recordings into {}\".format(directory))\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    for file in test_wannabe_i:\n",
    "        speaker_id = re.split('_',file)[0]\n",
    "        if not os.path.exists(directory + \"/\" + speaker_id):\n",
    "            os.makedirs(directory + \"/\" + speaker_id)\n",
    "        src = audio_path_i + \"/\" + file\n",
    "        dst = directory + \"/\" + speaker_id + \"/\" + file\n",
    "        copyfile(src, dst)\n",
    "print (\"loading finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI01MAX\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI29MBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI42FBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI44MBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI45FBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI55FBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI67MBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mUI03FAZ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  6 yehua  staff  204 Mar 29 00:29 \u001b[1m\u001b[36mUI08MAZ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  6 yehua  staff  204 Mar 29 00:29 \u001b[1m\u001b[36mUI29FAZ\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../interview_audio/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/interview_audio\n",
      "loading conversation recordings into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/interview_audio/test\n",
      "loading finished\n"
     ]
    }
   ],
   "source": [
    "# load conversation recordings into the test set\n",
    "from shutil import copyfile\n",
    "directory = parent_path + \"/audio\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "print (directory)\n",
    "directory += \"/test\"\n",
    "print (\"loading conversation recordings into {}\".format(directory))\n",
    "\n",
    "for file in test_wannabe_c:\n",
    "    speaker_id = re.split('_',file)[0][2:]\n",
    "    if not os.path.exists(directory + \"/\" + speaker_id):\n",
    "        os.makedirs(directory + \"/\" + speaker_id)\n",
    "    src = audio_path_c + \"/\" + file\n",
    "    dst = directory + \"/\" + speaker_id + \"/\" + file\n",
    "    newname = directory + \"/\" + speaker_id + \"/\" + file[2:]\n",
    "    copyfile(src, dst)\n",
    "    os.rename(dst, newname)\n",
    "print (\"loading finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:35 \u001b[1m\u001b[36mNC36MBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:35 \u001b[1m\u001b[36mNC37MBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:35 \u001b[1m\u001b[36mNC48FBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:35 \u001b[1m\u001b[36mNC61FBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI01MAX\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI29MBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI42FBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI44MBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI45FBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI55FBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mNI67MBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Mar 29 00:29 \u001b[1m\u001b[36mUI03FAZ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  6 yehua  staff  204 Mar 29 00:29 \u001b[1m\u001b[36mUI08MAZ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  6 yehua  staff  204 Mar 29 00:29 \u001b[1m\u001b[36mUI29FAZ\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../interview_audio/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 98328\r\n",
      "-rw-r--r--  1 yehua  staff  50340988 Mar 29 00:35 NC48FBP_0101.flac\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../interview_audio/test/NC48FBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading interview recordings into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/interview_audio/train\n",
      "loading finished\n"
     ]
    }
   ],
   "source": [
    "# loading interview recordings into the train set \n",
    "from shutil import copyfile\n",
    "directory = parent_path + \"/audio\"\n",
    "directory += \"/train\"\n",
    "print (\"loading interview recordings into {}\".format(directory))\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    for file in dir_list_i:\n",
    "        speaker_id = re.split('_',file)[0]\n",
    "        if speaker_id in train_ids_i:\n",
    "            if not os.path.exists(directory + \"/\" + speaker_id):\n",
    "                os.makedirs(directory + \"/\" + speaker_id)\n",
    "            src = audio_path_i + \"/\" + file\n",
    "            dst = directory + \"/\" + speaker_id + \"/\" + file\n",
    "            copyfile(src, dst)\n",
    "print (\"loading finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     148\r\n"
     ]
    }
   ],
   "source": [
    "ls -1 ../interview_audio/train | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "85+75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['22NC44MBQ', '08NC16FBQ', '02NC03FBX', '37NC45MBP']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_c[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "75\n",
      "speakers with multiple recordings:\n",
      " ['NC49FBQ', 'NC07FBX', 'NC37MBP', 'NC08FBY', 'NC50FBP', 'NC03FBX', 'NC44MBQ', 'NC22MBQ', 'NC06FAY', 'NC48FBP', 'NC35FBQ', 'NC10MAY', 'NC36MBQ', 'NC05FAX', 'NC43FBQ', 'NC41MBP', 'NC09FAX', 'NC45MBP', 'NC04FBY']\n"
     ]
    }
   ],
   "source": [
    "# find me conversation with different recordings under the same speaker \n",
    "train = ['22NC44MBQ', '08NC16FBQ', '02NC03FBX', '37NC45MBP', '46NC41MBP', '21NC41MBP', '29NC53MBP', '33NC37MBP', '06NC11MAX', '20NC40FBQ', '14NC27MBP', '13NC25MBP', '17NC33FBP', '40NC58FAY', '04NC08FBY', '14NC28MBQ', '45NC22MBQ', '04NC07FBX', '32NC36MBQ', '42NC60FBQ', '28NC51MBP', '44NC44MBQ', '33NC43FBQ', '25NC47MBP', '10NC19MBP', '39NC57FBX', '21NC42MBQ', '15NC29FBP', '20NC39MBP', '29NC54FBQ', '12NC24FBQ', '27NC47MBQ', '11NC21FBP', '24NC35FBQ', '05NC10MAY', '01NC02FBY', '18NC35FBP', '15NC30MBQ', '03NC05FAX', '13NC26MBQ', '30NC49FBQ', '23NC35FBQ', '28NC52FBQ', '41NC59MAX', '08NC15MBP', '05NC09FAX', '07NC13MBP', '07NC14FBQ', '10NC20MBQ', '03NC06FAY', '26NC49FBQ', '16NC32FBQ', '32NC50FBP', '19NC38FBQ', '24NC45MBP', '17NC34FBQ', '26NC48FBP', '01NC01FBX', '11NC22MBQ', '19NC37MBP', '16NC31FBP', '31NC35FBQ', '38NC50FBP', '36NC46FBQ', '25NC43FBQ', '35NC56MBP', '06NC12MAY', '09NC18MBQ', '22NC43FBP', '27NC50FBP', '12NC23FBP', '23NC45MBP', '09NC17FBP', '02NC04FBY', '31NC50XFB']\n",
    "speaker_multiple = []\n",
    "sets = set([])\n",
    "for i in train:\n",
    "    sets.add(i[2:])\n",
    "print (len(sets))\n",
    "print (len(train))\n",
    "\n",
    "dic = defaultdict(list)\n",
    "for file in dir_list_c:\n",
    "    dic[re.split(\"_\",file)[0][2:]].append(file)\n",
    "\n",
    "for key in dic:\n",
    "    if len(dic[key]) > 1 :\n",
    "        speaker_multiple.append(key)\n",
    "print (\"speakers with multiple recordings:\\n {}\".format(speaker_multiple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading interview recordings into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/interview_audio/train\n",
      "in multiple: \n",
      "02NC03FBX\n",
      "in multiple: \n",
      "02NC03FBX\n",
      "in multiple: \n",
      "02NC04FBY\n",
      "in multiple: \n",
      "02NC04FBY\n",
      "in multiple: \n",
      "03NC05FAX\n",
      "in multiple: \n",
      "03NC05FAX\n",
      "in multiple: \n",
      "03NC06FAY\n",
      "in multiple: \n",
      "03NC06FAY\n",
      "in multiple: \n",
      "04NC07FBX\n",
      "in multiple: \n",
      "04NC07FBX\n",
      "in multiple: \n",
      "04NC08FBY\n",
      "in multiple: \n",
      "04NC08FBY\n",
      "in multiple: \n",
      "05NC09FAX\n",
      "in multiple: \n",
      "05NC09FAX\n",
      "in multiple: \n",
      "05NC10MAY\n",
      "in multiple: \n",
      "05NC10MAY\n",
      "in multiple: \n",
      "11NC22MBQ\n",
      "in multiple: \n",
      "19NC37MBP\n",
      "in multiple: \n",
      "21NC41MBP\n",
      "in multiple: \n",
      "22NC44MBQ\n",
      "in multiple: \n",
      "23NC35FBQ\n",
      "in multiple: \n",
      "23NC45MBP\n",
      "in multiple: \n",
      "24NC35FBQ\n",
      "in multiple: \n",
      "24NC45MBP\n",
      "in multiple: \n",
      "25NC43FBQ\n",
      "in multiple: \n",
      "26NC48FBP\n",
      "in multiple: \n",
      "26NC49FBQ\n",
      "in multiple: \n",
      "27NC50FBP\n",
      "in multiple: \n",
      "30NC49FBQ\n",
      "in multiple: \n",
      "31NC35FBQ\n",
      "in multiple: \n",
      "32NC36MBQ\n",
      "in multiple: \n",
      "32NC50FBP\n",
      "in multiple: \n",
      "33NC37MBP\n",
      "in multiple: \n",
      "33NC43FBQ\n",
      "in multiple: \n",
      "37NC45MBP\n",
      "in multiple: \n",
      "38NC50FBP\n",
      "in multiple: \n",
      "44NC44MBQ\n",
      "in multiple: \n",
      "45NC22MBQ\n",
      "in multiple: \n",
      "46NC41MBP\n",
      "loading finished\n",
      "loaded 83 conversation recordings in to train set \n"
     ]
    }
   ],
   "source": [
    "# loading conversation recordings into the train set \n",
    "from shutil import copyfile\n",
    "directory = parent_path + \"/audio\"\n",
    "directory += \"/train\"\n",
    "print (\"loading conversation recordings into {}\".format(directory))\n",
    "counter = 0\n",
    "for file in dir_list_c:\n",
    "    speaker_id = re.split('_',file)[0]\n",
    "    if speaker_id in train_ids_c:\n",
    "        counter += 1\n",
    "        if not os.path.exists(directory + \"/\" + speaker_id[2:]):\n",
    "            os.makedirs(directory + \"/\" + speaker_id[2:])\n",
    "        src = audio_path_c + \"/\" + file\n",
    "        dst = directory + \"/\" + speaker_id[2:] + \"/\" + file\n",
    "        if speaker_id[2:] in speaker_multiple:\n",
    "            print (\" {} has multiple recordings under its name\".format(speaker_id))\n",
    "            pre = re.split(\"_\",file)[0][:2]\n",
    "            end = re.split(\"_\",file)[1].split(\".\")[0]\n",
    "            newfile = re.split(\"_\",file)[0][2:] + '_' + pre + end + \".flac\"\n",
    "\n",
    "            newname = directory + \"/\" + speaker_id[2:] + \"/\" + newfile\n",
    "            print (\"formated it from {} to {}\".format(file, newname))\n",
    "        \n",
    "        else: \n",
    "            newname = directory + \"/\" + speaker_id[2:] + \"/\" + file[2:]\n",
    "        copyfile(src, dst)\n",
    "        os.rename(dst, newname)\n",
    "        \n",
    "print (\"loading finished\")\n",
    "print (\"loaded {} conversation recordings in to train set \".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     148\r\n"
     ]
    }
   ],
   "source": [
    "ls -1 ../interview_audio/train | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14\r\n"
     ]
    }
   ],
   "source": [
    "ls -1 ../interview_audio/test | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC41MBP_210101.flac\r\n",
      "NC41MBP_460101.flac\r\n"
     ]
    }
   ],
   "source": [
    "ls -1 ../interview_audio/train/NC41MBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
