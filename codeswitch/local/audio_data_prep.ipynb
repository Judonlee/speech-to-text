{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the main module that structures the audio directory for Kaldi to consume  \\n   This script will prepare the audio directory as audio/<test || train>/<speaker id>/<recording>  \\n   e.g. audio/train/NC03FBX/NC03FBX_020101.flac  \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is the main module that structures the audio directory for Kaldi to consume  \n",
    "   This script will prepare the audio directory as audio/<test || train>/<speaker id>/<recording>  \n",
    "   e.g. audio/train/NC03FBX/NC03FBX_020101.flac  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__=\"Emily Hua\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "from shutil import rmtree\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to kaldi/egs/code-switch directory and create itnerview_audio folder. In kaldi-trunk/egs/code-switch/interview_audio create two folders: train and test. Select ten speaker of your choice to represent testing data set. Use this speaker's 'speakerID' as a name for an another new folder in kaldi-trunk/egs/code-switch/interview_audio/test directory. Then put there all the audio files related to that person. Put the rest (84 speakers) into train folder - this will be your training data set. Also create subfolders for each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8991184\r\n",
      "-rwxr-xr-x  1 yehua  staff  48047643 Feb 16 12:56 NI01MAX_0101.flac*\r\n",
      "-rwxr-xr-x  1 yehua  staff  50547368 Feb 16 12:56 NI02FAX_0101.flac*\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../LDC2015S04/seame_d2/data/interview/audio | head -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7925480\r\n",
      "-rwxr-xr-x  1 yehua  staff   95609160 Feb 16 12:51 01NC01FBX_0101.flac*\r\n",
      "-rwxr-xr-x  1 yehua  staff  123991309 Feb 16 12:51 01NC02FBY_0101.flac*\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../LDC2015S04/seame_d1/data/conversation/audio | head -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../LDC2015S04/seame_d1/data/conversation/audio/04NC08FBY_0101.flac\n",
      "../LDC2015S04/seame_d1/data/conversation/audio/04NC08FBY_0201.flac\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# look out for this speaker who is an exmaple of having multuple files under the name NC08FBY\n",
    "find ../LDC2015S04/seame_d1/data/conversation/audio -type f -print | grep 'NC08FBY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the parent path is /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch\n"
     ]
    }
   ],
   "source": [
    "parent_path = os.path.split(os.getcwd())[0]\n",
    "print (\"the parent path is {}\".format(parent_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = parent_path+\"/audio/test\"\n",
    "if os.path.exists(directory):\n",
    "    clean_up(directory) # remove whatever is already in the train directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls -l ../audio/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are total 210 of files in /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/LDC2015S04/seame_d2/data/interview/audio\n",
      "\n",
      "there are total 87 of files in /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/LDC2015S04/seame_d1/data/conversation/audio\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_file_list(audio_path, dirn):\n",
    "    r\"\"\"Count the number of recordings in Conversation and Interview directories, return a list of file names\n",
    "    Returns\n",
    "    -------\n",
    "    dir_list : list\n",
    "        a list of file names under the corresponding Conversation or Interview's audio directory\n",
    "    \"\"\"\n",
    "    dir_list = os.listdir(audio_path)\n",
    "    dir_list = [f for f in os.listdir(audio_path) if re.match(r'[^\\\\]+\\.flac', f)] # makes sure unwanted files like .DS_Store doesn't show up here! \n",
    "    print (\"there are total {} of files in {}\\n\".format(len(dir_list), audio_path))\n",
    "    if dirn == 'interview':\n",
    "        assert (len(dir_list) == 210), 'LDC2015S04/seame_d1/data/interview/audio should have 210 recordings, check if the directory is corrupted'\n",
    "    else:\n",
    "        assert (len(dir_list) == 87), 'LDC2015S04/seame_d2/data/conversation/audio should have 87 recordings, check if the directory is corrupted'\n",
    "    return dir_list\n",
    "\n",
    "audio_path_i = parent_path + '/LDC2015S04/seame_d2/data/interview/audio'\n",
    "audio_path_c = parent_path + '/LDC2015S04/seame_d1/data/conversation/audio'\n",
    "dir_list_i = get_file_list(audio_path_i, 'interview')\n",
    "dir_list_c = get_file_list(audio_path_c, 'conversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 95 unique prefix sets\n",
      "there are 79 unique prefix sets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def speaker_re_counts(dir_list):\n",
    "    r\"\"\"Create a dictionary mapping of prefix to the number of recordings under this prefix. \n",
    "    Returns\n",
    "    -------\n",
    "    id_dic : collections.defaultdict\n",
    "        a dictionary with key as recording prefix (tentative speaker id) and number of files associated with this prefix\n",
    "        e.g. (interview) 'NI52MBQ': 2\n",
    "        e.g. (conversation) '37NC45MBP': 1\n",
    "    \"\"\"\n",
    "    id_dic = defaultdict(int)\n",
    "    for file in dir_list:\n",
    "        id_dic[re.split('_', file)[0]] += 1\n",
    "    #print ('there are {} unique prefix sets'.format(len(id_dic)))\n",
    "    return id_dic\n",
    "id_dic_i = speaker_re_counts(dir_list_i)\n",
    "id_dic_c = speaker_re_counts(dir_list_c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 64 unique prefix sets\n"
     ]
    }
   ],
   "source": [
    "# no need to be included in the final script  \n",
    "id_dic_cc = defaultdict(int)\n",
    "for file in dir_list_c:\n",
    "    id_dic_cc[re.split('_', file)[0][2:]] += 1\n",
    "print ('there are {} unique prefix sets'.format(len(id_dic_cc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample speaker ids and number of recordings in converstaion: {'28NC51MBP': 1, '37NC45MBP': 1, '36NC46FBQ': 1}\n"
     ]
    }
   ],
   "source": [
    "# no need to be included in the final script  \n",
    "print (\"sample speaker ids and number of recordings in converstaion: {}\".format(dict(list(id_dic_c.items())[:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample speaker ids and number of recordings in interview: {'NI52MBQ': 2, 'UI26MAZ': 5, 'UI19MAZ': 5}\n"
     ]
    }
   ],
   "source": [
    "# no need to be included in the final script   \n",
    "print (\"sample speaker ids and number of recordings in interview: {}\".format(dict(list(id_dic_i.items())[:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_short_ids_i = ['01MA', '03FA','08MA', '29FA','29MB','42FB','44MB','45FB','67MB','55FB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_short_ids_c = ['01NC01FB', '01NC02FB','06NC11MA', '06NC12MA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 85 unprocessed speaker ids in the training set\n",
      "there are 10 unprocessed speaker ids in the testing set\n",
      "\n",
      "there are 75 unprocessed speaker ids in the training set\n",
      "there are 4 unprocessed speaker ids in the testing set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(id_dic, test_short_ids, dirn):\n",
    "    r\"\"\"generate a list of speaker id that should be the train or test set \n",
    "    Returns\n",
    "    -------\n",
    "    train_ids, test_ids : list, list\n",
    "        a list of ids that belong to train or test set \n",
    "        e.g. (interview train) 'NI52MBQ' (interview test) 'NI55FBP'\n",
    "        e.g. (conversation train) '37NC45MBP' (interview test) '01NC02FBY'\n",
    "    \"\"\"\n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "    for key in id_dic:\n",
    "        if key[2:-1] in test_short_ids or key[:-1] in test_short_ids:\n",
    "            test_ids.append(key)\n",
    "        else: \n",
    "            train_ids.append(key)\n",
    "    print ('there are {} unprocessed speaker ids in the training set'.format(len(train_ids)))\n",
    "    print ('there are {} unprocessed speaker ids in the testing set\\n'.format(len(test_ids)))\n",
    "    \n",
    "    if dirn == \"interview\":\n",
    "        assert (len(train_ids) == 85 and len(test_ids) == 10), \"For interview, there should be 85 speakers be moved to the training set, 10 speakers in test set\"\n",
    "    else:\n",
    "        assert (len(train_ids) == 75 and len(test_ids) == 4), \"For conversation, there should be 75 speakers be moved to the training set, 4 speakers in test set\"\n",
    "    \n",
    "    return train_ids, test_ids\n",
    "train_ids_i, test_ids_i = train_test_split(id_dic_i, test_short_ids_i, \"interview\")\n",
    "train_ids_c, test_ids_c = train_test_split(id_dic_c, test_short_ids_c, \"conversation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 85 speaker ids in the training set\n",
    "there are 10 speaker ids in the testing set\n",
    "\n",
    "there are 75 speaker ids (60 after process) in the training set\n",
    "there are 4 speaker ids in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker ids in the converation test set: ['01NC02FBY', '06NC12MAY', '01NC01FBX', '06NC11MAX']\n",
      "\n",
      "speaker ids in the interview test set: ['NI55FBP', 'UI08MAZ', 'NI67MBQ', 'NI45FBP', 'NI29MBP', 'NI42FBQ', 'UI29FAZ', 'NI01MAX', 'NI44MBQ', 'UI03FAZ']\n"
     ]
    }
   ],
   "source": [
    "# no need to be included in the final script \n",
    "print (\"speaker ids in the converation test set: {}\\n\".format(test_ids_c))\n",
    "print (\"speaker ids in the interview test set: {}\".format(test_ids_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ids_c_short = set([x[2:] for x in train_ids_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no need to be included in the final script \n",
    "len(train_ids_c_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NC47MBP', 'NC35FBQ', 'NC17FBP', 'NC54FBQ', 'NC35FBP', 'NC23FBP', 'NC39MBP', 'NC07FBX', 'NC33FBP', 'NC59MAX', 'NC08FBY', 'NC28MBQ', 'NC22MBQ', 'NC20MBQ', 'NC16FBQ', 'NC03FBX', 'NC42MBQ', 'NC43FBQ', 'NC05FAX', 'NC09FAX', 'NC52FBQ', 'NC49FBQ', 'NC47MBQ', 'NC13MBP', 'NC36MBQ', 'NC46FBQ', 'NC40FBQ', 'NC25MBP', 'NC27MBP', 'NC15MBP', 'NC32FBQ', 'NC61FBQ', 'NC29FBP', 'NC43FBP', 'NC51MBP', 'NC56MBP', 'NC30MBQ', 'NC53MBP', 'NC44MBQ', 'NC37MBP', 'NC18MBQ', 'NC50FBP', 'NC04FBY', 'NC60FBQ', 'NC41MBP', 'NC34FBQ', 'NC38FBQ', 'NC26MBQ', 'NC14FBQ', 'NC45MBP', 'NC50XFB', 'NC57FBX', 'NC06FAY', 'NC24FBQ', 'NC48FBP', 'NC31FBP', 'NC10MAY', 'NC21FBP', 'NC19MBP', 'NC58FAY'}\n"
     ]
    }
   ],
   "source": [
    "# no need to be included in the final script \n",
    "print (train_ids_c_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker ids in the conversation train set: \n",
      "['37NC45MBP', '28NC51MBP', '36NC46FBQ', '19NC37MBP', '39NC57FBX', '07NC13MBP', '26NC48FBP', '10NC19MBP', '25NC47MBP', '13NC25MBP', '02NC04FBY', '33NC37MBP', '07NC14FBQ', '43NC61FBQ', '31NC50XFB', '14NC28MBQ', '24NC35FBQ', '46NC41MBP', '09NC18MBQ', '45NC22MBQ', '28NC52FBQ', '11NC21FBP', '14NC27MBP', '21NC41MBP', '34NC37MBP', '26NC49FBQ', '17NC33FBP', '25NC43FBQ', '21NC42MBQ', '30NC48FBP', '22NC43FBP', '15NC30MBQ', '23NC45MBP', '27NC50FBP', '02NC03FBX', '17NC34FBQ', '12NC24FBQ', '33NC43FBQ', '05NC09FAX', '08NC16FBQ', '15NC29FBP', '22NC44MBQ', '09NC17FBP', '31NC35FBQ', '23NC35FBQ', '11NC22MBQ', '27NC47MBQ', '35NC56MBP', '18NC35FBP', '18NC36MBQ', '29NC54FBQ', '05NC10MAY', '08NC15MBP', '44NC44MBQ', '03NC06FAY', '41NC59MAX', '04NC08FBY', '12NC23FBP', '32NC50FBP', '03NC05FAX', '30NC49FBQ', '20NC39MBP', '04NC07FBX', '38NC50FBP', '24NC45MBP', '19NC38FBQ', '16NC32FBQ', '10NC20MBQ', '29NC53MBP', '40NC58FAY', '13NC26MBQ', '16NC31FBP', '20NC40FBQ', '32NC36MBQ', '42NC60FBQ']\n",
      "\n",
      "speaker ids in the interview train set: \n",
      "['NI52MBQ', 'UI26MAZ', 'UI19MAZ', 'NI43FBP', 'NI26FBP', 'UI24MAZ', 'NI16FBP', 'NI64FBQ', 'UI25FAZ', 'NI11FBP', 'UI20MAZ', 'UI09MAZ', 'NI37MBP', 'NI28MBP', 'UI10FAZ', 'UI21MAZ', 'NI13MBQ', 'UI11FAZ', 'UI17FAZ', 'NI33MBP', 'NI46FBQ', 'NI61FBP', 'NI12MAP', 'UI14MAZ', 'NI08FBP', 'NI54FBQ', 'UI15FAZ', 'NI62MBQ', 'UI13FAZ', 'UI01FAZ', 'NI20MBP', 'NI24MBP', 'NI34FBQ', 'NI47MBP', 'NI36MBQ', 'UI02FAZ', 'NI50FBQ', 'NI40FBQ', 'NI65MBP', 'NI58FBP', 'UI22MAZ', 'UI04FAZ', 'NI23FBQ', 'NI51MBP', 'UI27FAZ', 'NI14MBP', 'NI02FAX', 'NI30MBQ', 'NI05MBQ', 'UI23FAZ', 'UI16MAZ', 'NI60MBP', 'NI39FBP', 'NI10FBP', 'UI12FAZ', 'NI19MBQ', 'NI06FBP', 'NI21MBQ', 'NI17FBQ', 'NI35FBP', 'NI56MBX', 'NI27MBQ', 'NI04FBX', 'NI25MBQ', 'NI49MBP', 'UI28FAZ', 'UI07FAZ', 'NI32FBQ', 'NI63MBP', 'NI15FBQ', 'NI09FBP', 'NI41MBP', 'UI06MAZ', 'NI57FBQ', 'NI03FBX', 'NI07FBQ', 'UI18MAZ', 'UI05MAZ', 'NI22FBP', 'NI31FBP', 'NI66MBQ', 'NI59FBQ', 'NI18MBP', 'NI53FBP', 'NI48FBQ']\n"
     ]
    }
   ],
   "source": [
    "# no need to be included in the final script \n",
    "print (\"speaker ids in the conversation train set: \\n{}\\n\".format(train_ids_c))\n",
    "print (\"speaker ids in the interview train set: \\n{}\".format(train_ids_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 16 files ready to be moved into the test set\n",
      "there are 4 files ready to be moved into the test set\n"
     ]
    }
   ],
   "source": [
    "def create_test_wannabe(dir_list, test_ids, dirn):\n",
    "    r\"\"\"generate a list of recording file name that should be moved to the test set \n",
    "    Returns\n",
    "    -------\n",
    "    test_wannabe : list\n",
    "        a list of file names that we moved to test set\n",
    "        e.g. (interview) 'NI01MAX_0101.flac'\n",
    "        e.g. (conversation) '01NC01FBX_0101.flac'\n",
    "    \"\"\"\n",
    "    test_wannabe = []\n",
    "    for file in dir_list:\n",
    "        speaker_id = re.split('_', file)[0]\n",
    "        if speaker_id in test_ids:\n",
    "            test_wannabe.append(file)\n",
    "            # I have add a file from this prefix into the test set, no need for more from this prefix\n",
    "    print (\"there are {} files ready to be moved into the test set\".format(len(test_wannabe)))\n",
    "    if dirn == \"interview\":\n",
    "        assert (len(test_wannabe) == 16), \"16 files from interview should be moved into the test set\"\n",
    "    else:\n",
    "        assert (len(test_wannabe) == 4), \"4 files from conversation should be moved into the test set\"    \n",
    "    return test_wannabe\n",
    "\n",
    "test_wannabe_i = create_test_wannabe(dir_list_i, test_ids_i, \"interview\")\n",
    "test_wannabe_c = create_test_wannabe(dir_list_c, test_ids_c, \"conversation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be   \n",
    "there are 16 files ready to be moved into the test set  \n",
    "there are 4 files ready to be moved into the test set  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x   16 yehua  staff   544 Apr  6 22:12 \u001b[1m\u001b[36mtest\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  148 yehua  staff  5032 Apr  7 21:59 \u001b[1m\u001b[36mtrain\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../audio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load interview recordings into the test folder\n",
    "    \n",
    "# def load_test_interview():\n",
    "#     directory += \"/test\"\n",
    "#     print (\"....loading interview recordings into {}\".format(directory))\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "#         for file in test_wannabe_i:\n",
    "#             speaker_id = re.split('_',file)[0]\n",
    "#             if not os.path.exists(directory + \"/\" + speaker_id):\n",
    "#                 os.makedirs(directory + \"/\" + speaker_id)\n",
    "#             src = audio_path_i + \"/\" + file\n",
    "#             dst = directory + \"/\" + speaker_id + \"/\" + file\n",
    "#             copyfile(src, dst)\n",
    "#     print (\"loading finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_up (dir_path):\n",
    "    files = glob.glob(dir_path+'/*')\n",
    "    for f in files:\n",
    "        rmtree(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_audios_to_test(test_files_list,audio_path, dirn):\n",
    "    counter = 0\n",
    "    directory = parent_path + \"/audio\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    directory += \"/test\"\n",
    "    print (\"loading {} recordings into {}\".format(dirn, directory))\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)        \n",
    "    for file in test_files_list:\n",
    "        if dirn == \"interview\":\n",
    "            speaker_id = re.split('_',file)[0]\n",
    "        elif dirn ==\"conversation\":\n",
    "            speaker_id = re.split('_',file)[0][2:]\n",
    "        if not os.path.exists(directory + \"/\" + speaker_id):\n",
    "            os.makedirs(directory + \"/\" + speaker_id)\n",
    "        src = audio_path + \"/\" + file\n",
    "        dst = directory + \"/\" + speaker_id + \"/\" + file\n",
    "        copyfile(src, dst)\n",
    "        counter += 1\n",
    "    if dirn == \"interview\":\n",
    "        assert (counter == 16), \"should move 16 interview files to test folder, the number mismatched, investigate!\"\n",
    "    else:\n",
    "        assert (counter == 4), \"should move 4 conversation files to test folder, the number mismatched, investigate!\"\n",
    "    print (\"loading {} to test finished!\".format(dirn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading interview recordings into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/test\n",
      "loading interview to test finished!\n",
      "loading conversation recordings into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/test\n",
      "loading conversation to test finished!\n"
     ]
    }
   ],
   "source": [
    "load_audios_to_test(test_wannabe_i, audio_path_i, \"interview\")\n",
    "load_audios_to_test(test_wannabe_c, audio_path_c, \"conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio\n",
      "loading conversation recordings into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/test\n",
      "loading finished\n"
     ]
    }
   ],
   "source": [
    "# # load conversation recordings into the test set\n",
    "# from shutil import copyfile\n",
    "# directory = parent_path + \"/audio\"\n",
    "# if not os.path.exists(directory):\n",
    "#     os.makedirs(directory)\n",
    "# print (directory)\n",
    "# directory += \"/test\"\n",
    "# print (\"loading conversation recordings into {}\".format(directory))\n",
    "\n",
    "# for file in test_wannabe_c:\n",
    "#     speaker_id = re.split('_',file)[0][2:]\n",
    "#     if not os.path.exists(directory + \"/\" + speaker_id):\n",
    "#         os.makedirs(directory + \"/\" + speaker_id)\n",
    "#     src = audio_path_c + \"/\" + file\n",
    "#     dst = directory + \"/\" + speaker_id + \"/\" + file\n",
    "#     newname = directory + \"/\" + speaker_id + \"/\" + file[2:]\n",
    "#     copyfile(src, dst)\n",
    "#     os.rename(dst, newname)\n",
    "# print (\"loading finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:19 \u001b[1m\u001b[36mNC01FBX\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:19 \u001b[1m\u001b[36mNC02FBY\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:19 \u001b[1m\u001b[36mNC11MAX\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:19 \u001b[1m\u001b[36mNC12MAY\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI01MAX\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI29MBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI42FBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI44MBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI45FBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI55FBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI67MBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mUI03FAZ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  6 yehua  staff  204 Apr 13 17:20 \u001b[1m\u001b[36mUI08MAZ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  6 yehua  staff  204 Apr 13 17:20 \u001b[1m\u001b[36mUI29FAZ\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../audio/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:19 \u001b[1m\u001b[36mNC01FBX\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:19 \u001b[1m\u001b[36mNC02FBY\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:19 \u001b[1m\u001b[36mNC11MAX\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:19 \u001b[1m\u001b[36mNC12MAY\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI01MAX\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI29MBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI42FBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI44MBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI45FBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI55FBP\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mNI67MBQ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr 13 17:20 \u001b[1m\u001b[36mUI03FAZ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  6 yehua  staff  204 Apr 13 17:20 \u001b[1m\u001b[36mUI08MAZ\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  6 yehua  staff  204 Apr 13 17:20 \u001b[1m\u001b[36mUI29FAZ\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../audio/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 186744\r\n",
      "-rw-r--r--  1 yehua  staff  95609160 Apr 13 17:20 01NC01FBX_0101.flac\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../audio/test/NC01FBX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_interview_train(dir_list):\n",
    "    r\"\"\" loading corresponding interview recordings to the training directory \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    directory = parent_path + \"/audio\"\n",
    "    directory += \"/train\"\n",
    "    print (\"loading interview recordings into {}\".format(directory))\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    else:\n",
    "        clean_up(directory) # remove whatever is already in the train directory\n",
    "    \n",
    "    for file in dir_list:\n",
    "        speaker_id = re.split('_',file)[0]\n",
    "        if speaker_id in train_ids_i:\n",
    "            if not os.path.exists(directory + \"/\" + speaker_id):\n",
    "                os.makedirs(directory + \"/\" + speaker_id)\n",
    "            src = audio_path_i + \"/\" + file\n",
    "            dst = directory + \"/\" + speaker_id + \"/\" + file\n",
    "            copyfile(src, dst)\n",
    "    print (\"loading finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading interview recordings into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train\n",
      "loading finished\n"
     ]
    }
   ],
   "source": [
    "load_interview_train(dir_list_i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      85\r\n"
     ]
    }
   ],
   "source": [
    "ls -1 ../audio/train | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "85+75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['22NC44MBQ', '08NC16FBQ', '02NC03FBX', '37NC45MBP']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_c[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'04NC08FBY' in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'04NC08FBY' inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'NC08FBY' in speaker_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04NC08FBY_0101.flac\n",
      "04NC08FBY_0201.flac\n"
     ]
    }
   ],
   "source": [
    "for i in dir_list_c:\n",
    "    if '04NC08FBY' in i:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04NC08FBY_0101.flac', '04NC08FBY_0201.flac']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['NC08FBY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speaker_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find me conversation with different recordings under the same speaker \n",
    "# train = ['15NC29FBP', '29NC53MBP', '28NC52FBQ', '20NC39MBP', '04NC08FBY', '10NC20MBQ', '19NC37MBP', '40NC58FAY', '23NC45MBP', '46NC41MBP', '07NC14FBQ', '32NC36MBQ', '12NC24FBQ', '34NC37MBP', '13NC25MBP', '28NC51MBP', '31NC35FBQ', '25NC43FBQ', '26NC49FBQ', '31NC50XFB', '14NC28MBQ', '44NC44MBQ', '03NC06FAY', '33NC43FBQ', '09NC17FBP', '04NC07FBX', '45NC22MBQ', '26NC48FBP', '37NC45MBP', '27NC47MBQ', '18NC36MBQ', '15NC30MBQ', '02NC03FBX', '05NC10MAY', '03NC05FAX', '32NC50FBP', '36NC46FBQ', '11NC21FBP', '35NC56MBP', '11NC22MBQ', '19NC38FBQ', '22NC43FBP', '12NC23FBP', '29NC54FBQ', '07NC13MBP', '39NC57FBX', '25NC47MBP', '08NC16FBQ', '22NC44MBQ', '21NC41MBP', '17NC33FBP', '16NC31FBP', '08NC15MBP', '18NC35FBP', '05NC09FAX', '09NC18MBQ', '14NC27MBP', '42NC60FBQ', '17NC34FBQ', '30NC48FBP', '10NC19MBP', '41NC59MAX', '24NC35FBQ', '43NC61FBQ', '24NC45MBP', '27NC50FBP', '13NC26MBQ', '33NC37MBP', '30NC49FBQ', '16NC32FBQ', '02NC04FBY', '20NC40FBQ', '38NC50FBP', '23NC35FBQ', '21NC42MBQ']\n",
    "def get_speaker_multiple(ids):\n",
    "    r\"\"\"generate a list of recording prefix which recordings need to be renamed \n",
    "    Returns\n",
    "    -------\n",
    "    speaker_multiple : list\n",
    "        a list of speaker ids that have multiple files under its name, and need to be renamed \n",
    "    \"\"\"\n",
    "    speaker_multiple = []\n",
    "    sets = set([])\n",
    "    for i in ids:\n",
    "        sets.add(i[2:])\n",
    "\n",
    "    dic = defaultdict(list)\n",
    "    for file in dir_list_c:\n",
    "        dic[re.split(\"_\",file)[0][2:]].append(file)\n",
    "\n",
    "    for key in dic:\n",
    "        if len(dic[key]) > 1 :\n",
    "            speaker_multiple.append(key)\n",
    "    print (\"speakers with multiple recordings:\\n {}\".format(speaker_multiple))\n",
    "    return speaker_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speakers with multiple recordings:\n",
      " ['NC35FBQ', 'NC06FAY', 'NC48FBP', 'NC08FBY', 'NC22MBQ', 'NC03FBX', 'NC49FBQ', 'NC43FBQ', 'NC09FAX', 'NC36MBQ', 'NC07FBX', 'NC44MBQ', 'NC37MBP', 'NC04FBY', 'NC41MBP', 'NC50FBP', 'NC45MBP', 'NC05FAX', 'NC10MAY']\n"
     ]
    }
   ],
   "source": [
    "speaker_multiple = get_speaker_multiple(train_ids_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for f in dir_list_c:\n",
    "    for n in train_ids_c:\n",
    "        if n in f:\n",
    "            c += 1\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_conversation_train():\n",
    "    r\"\"\"loading corresponding conversation recordings into the train set\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    directory = parent_path + \"/audio\"\n",
    "    directory += \"/train\"\n",
    "    print (\"loading conversation recordings into {}\".format(directory))\n",
    "    counter = 0\n",
    "    for file in dir_list_c:\n",
    "        speaker_id = re.split('_',file)[0]\n",
    "        if speaker_id in train_ids_c:\n",
    "            counter += 1\n",
    "            if not os.path.exists(directory + \"/\" + speaker_id[2:]):\n",
    "                os.makedirs(directory + \"/\" + speaker_id[2:])\n",
    "            src = audio_path_c + \"/\" + file\n",
    "            dst = directory + \"/\" + speaker_id[2:] + \"/\" + file\n",
    "            if speaker_id[2:] in speaker_multiple:\n",
    "                print (\" {} has multiple recordings under its name\".format(speaker_id))\n",
    "                pre = re.split(\"_\",file)[0][:2]\n",
    "                end = re.split(\"_\",file)[1].split(\".\")[0]\n",
    "                newfile = re.split(\"_\",file)[0][2:] + '_' + pre + end + \".flac\"\n",
    "\n",
    "                newname = directory + \"/\" + speaker_id[2:] + \"/\" + newfile\n",
    "                print (\"formated it from {} to {}\".format(file, newname))\n",
    "\n",
    "            else: \n",
    "                newname = directory + \"/\" + speaker_id[2:] + \"/\" + file[2:]\n",
    "            copyfile(src, dst)\n",
    "            os.rename(dst, newname)\n",
    "    assert (counter == 83), \"should move 83 files from conversation to the train folder, the number mismatched, investigate\"\n",
    "    print (\"loading finished\")\n",
    "    print (\"loaded {} conversation recordings in to train set \".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading conversation recordings into /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train\n",
      " 02NC03FBX has multiple recordings under its name\n",
      "formated it from 02NC03FBX_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC03FBX/NC03FBX_020101.flac\n",
      " 02NC03FBX has multiple recordings under its name\n",
      "formated it from 02NC03FBX_0201.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC03FBX/NC03FBX_020201.flac\n",
      " 02NC04FBY has multiple recordings under its name\n",
      "formated it from 02NC04FBY_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC04FBY/NC04FBY_020101.flac\n",
      " 02NC04FBY has multiple recordings under its name\n",
      "formated it from 02NC04FBY_0201.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC04FBY/NC04FBY_020201.flac\n",
      " 03NC05FAX has multiple recordings under its name\n",
      "formated it from 03NC05FAX_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC05FAX/NC05FAX_030101.flac\n",
      " 03NC05FAX has multiple recordings under its name\n",
      "formated it from 03NC05FAX_0201.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC05FAX/NC05FAX_030201.flac\n",
      " 03NC06FAY has multiple recordings under its name\n",
      "formated it from 03NC06FAY_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC06FAY/NC06FAY_030101.flac\n",
      " 03NC06FAY has multiple recordings under its name\n",
      "formated it from 03NC06FAY_0201.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC06FAY/NC06FAY_030201.flac\n",
      " 04NC07FBX has multiple recordings under its name\n",
      "formated it from 04NC07FBX_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC07FBX/NC07FBX_040101.flac\n",
      " 04NC07FBX has multiple recordings under its name\n",
      "formated it from 04NC07FBX_0201.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC07FBX/NC07FBX_040201.flac\n",
      " 04NC08FBY has multiple recordings under its name\n",
      "formated it from 04NC08FBY_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC08FBY/NC08FBY_040101.flac\n",
      " 04NC08FBY has multiple recordings under its name\n",
      "formated it from 04NC08FBY_0201.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC08FBY/NC08FBY_040201.flac\n",
      " 05NC09FAX has multiple recordings under its name\n",
      "formated it from 05NC09FAX_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC09FAX/NC09FAX_050101.flac\n",
      " 05NC09FAX has multiple recordings under its name\n",
      "formated it from 05NC09FAX_0201.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC09FAX/NC09FAX_050201.flac\n",
      " 05NC10MAY has multiple recordings under its name\n",
      "formated it from 05NC10MAY_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC10MAY/NC10MAY_050101.flac\n",
      " 05NC10MAY has multiple recordings under its name\n",
      "formated it from 05NC10MAY_0201.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC10MAY/NC10MAY_050201.flac\n",
      " 11NC22MBQ has multiple recordings under its name\n",
      "formated it from 11NC22MBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC22MBQ/NC22MBQ_110101.flac\n",
      " 18NC36MBQ has multiple recordings under its name\n",
      "formated it from 18NC36MBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC36MBQ/NC36MBQ_180101.flac\n",
      " 19NC37MBP has multiple recordings under its name\n",
      "formated it from 19NC37MBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC37MBP/NC37MBP_190101.flac\n",
      " 21NC41MBP has multiple recordings under its name\n",
      "formated it from 21NC41MBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC41MBP/NC41MBP_210101.flac\n",
      " 22NC44MBQ has multiple recordings under its name\n",
      "formated it from 22NC44MBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC44MBQ/NC44MBQ_220101.flac\n",
      " 23NC35FBQ has multiple recordings under its name\n",
      "formated it from 23NC35FBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC35FBQ/NC35FBQ_230101.flac\n",
      " 23NC45MBP has multiple recordings under its name\n",
      "formated it from 23NC45MBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC45MBP/NC45MBP_230101.flac\n",
      " 24NC35FBQ has multiple recordings under its name\n",
      "formated it from 24NC35FBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC35FBQ/NC35FBQ_240101.flac\n",
      " 24NC45MBP has multiple recordings under its name\n",
      "formated it from 24NC45MBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC45MBP/NC45MBP_240101.flac\n",
      " 25NC43FBQ has multiple recordings under its name\n",
      "formated it from 25NC43FBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC43FBQ/NC43FBQ_250101.flac\n",
      " 26NC48FBP has multiple recordings under its name\n",
      "formated it from 26NC48FBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC48FBP/NC48FBP_260101.flac\n",
      " 26NC49FBQ has multiple recordings under its name\n",
      "formated it from 26NC49FBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC49FBQ/NC49FBQ_260101.flac\n",
      " 27NC50FBP has multiple recordings under its name\n",
      "formated it from 27NC50FBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC50FBP/NC50FBP_270101.flac\n",
      " 30NC48FBP has multiple recordings under its name\n",
      "formated it from 30NC48FBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC48FBP/NC48FBP_300101.flac\n",
      " 30NC49FBQ has multiple recordings under its name\n",
      "formated it from 30NC49FBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC49FBQ/NC49FBQ_300101.flac\n",
      " 31NC35FBQ has multiple recordings under its name\n",
      "formated it from 31NC35FBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC35FBQ/NC35FBQ_310101.flac\n",
      " 32NC36MBQ has multiple recordings under its name\n",
      "formated it from 32NC36MBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC36MBQ/NC36MBQ_320101.flac\n",
      " 32NC50FBP has multiple recordings under its name\n",
      "formated it from 32NC50FBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC50FBP/NC50FBP_320101.flac\n",
      " 33NC37MBP has multiple recordings under its name\n",
      "formated it from 33NC37MBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC37MBP/NC37MBP_330101.flac\n",
      " 33NC43FBQ has multiple recordings under its name\n",
      "formated it from 33NC43FBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC43FBQ/NC43FBQ_330101.flac\n",
      " 34NC37MBP has multiple recordings under its name\n",
      "formated it from 34NC37MBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC37MBP/NC37MBP_340101.flac\n",
      " 37NC45MBP has multiple recordings under its name\n",
      "formated it from 37NC45MBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC45MBP/NC45MBP_370101.flac\n",
      " 38NC50FBP has multiple recordings under its name\n",
      "formated it from 38NC50FBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC50FBP/NC50FBP_380101.flac\n",
      " 44NC44MBQ has multiple recordings under its name\n",
      "formated it from 44NC44MBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC44MBQ/NC44MBQ_440101.flac\n",
      " 45NC22MBQ has multiple recordings under its name\n",
      "formated it from 45NC22MBQ_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC22MBQ/NC22MBQ_450101.flac\n",
      " 46NC41MBP has multiple recordings under its name\n",
      "formated it from 46NC41MBP_0101.flac to /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/audio/train/NC41MBP/NC41MBP_460101.flac\n",
      "loading finished\n",
      "loaded 83 conversation recordings in to train set \n"
     ]
    }
   ],
   "source": [
    "load_conversation_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     145\r\n"
     ]
    }
   ],
   "source": [
    "ls -1 ../audio/train | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14\r\n"
     ]
    }
   ],
   "source": [
    "ls -1 ../audio/test | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC08FBY_040101.flac\r\n",
      "NC08FBY_040201.flac\r\n"
     ]
    }
   ],
   "source": [
    "ls -1 ../interview_audio/train/NC08FBY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
