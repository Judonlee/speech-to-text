{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__=\"Emily Hua\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to create some text files that will allow Kaldi to communicate with your audio data. Consider these files as 'must be done'. Each file that you will create in this section (and in Language data section as well) can be considered as a text file with some number of strings (each string in a new line). These strings need to be sorted. If you will encounter any sorting issues you can use Kaldi scripts for checking (utils/validate_data_dir.sh) and fixing (utils/fix_data_dir.sh) data order. And for you information - utils directory will be attached to your project in Tools attachment section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "from shutil import rmtree\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch\n"
     ]
    }
   ],
   "source": [
    "parent_path = os.path.split(os.getcwd())[0]\n",
    "print (parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 199680\r\n",
      "-rw-r--r--  1 yehua  staff  51933995 Apr 13 17:59 NC03FBX_020101.flac\r\n",
      "-rw-r--r--  1 yehua  staff  50297952 Apr 13 17:59 NC03FBX_020201.flac\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../audio/train/NC03FBX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In kaldi/egs/code-switch directory, create a folder **data**. Then create **test** and **train** subfolders inside. Create in each subfolder following files (so you have files named in the same way in test and train subfolders but they relate to two different data sets that you created before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makedir(dirt):\n",
    "    r\"\"\"create data/train or data/test directory\n",
    "    \"\"\"\n",
    "    directory = parent_path + \"/data/\" + dirt\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "makedir(\"train\")\n",
    "makedir(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  3 yehua  staff  102 Apr  7 22:55 \u001b[1m\u001b[36mlang\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  4 yehua  staff  136 Apr  7 22:54 \u001b[1m\u001b[36mlocal\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  9 yehua  staff  306 Apr  4 17:09 \u001b[1m\u001b[36mtest\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  9 yehua  staff  306 Apr  4 17:27 \u001b[1m\u001b[36mtrain\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 23448\r\n",
      "-rw-r--r--  1 yehua  staff  2505625 Apr  6 21:30 segments\r\n",
      "-rw-r--r--@ 1 yehua  staff     1600 Apr  6 21:30 spk2gender\r\n",
      "-rw-r--r--  1 yehua  staff  3929042 Apr  6 21:30 text\r\n",
      "-rw-r--r--  1 yehua  staff  3929042 Apr  4 16:56 text_filtered\r\n",
      "-rw-r--r--  1 yehua  staff  1586903 Apr  6 21:30 utt2spk\r\n",
      "-rw-r--r--  1 yehua  staff    38394 Apr  6 21:30 wav.scp\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1960\r\n",
      "-rw-r--r--  1 yehua  staff  193371 Apr  6 21:30 segments\r\n",
      "-rw-r--r--  1 yehua  staff     140 Apr  6 21:30 spk2gender\r\n",
      "-rw-r--r--  1 yehua  staff  331887 Apr  6 21:30 text\r\n",
      "-rw-r--r--  1 yehua  staff  331887 Apr  4 16:59 text_filtered\r\n",
      "-rw-r--r--  1 yehua  staff  123247 Apr  6 21:30 utt2spk\r\n",
      "-rw-r--r--  1 yehua  staff    2740 Apr  6 21:30 wav.scp\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../data/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.) spk2gender \n",
    "This file informs about speakers gender. As we assumed, 'speakerID' is a unique name of each speaker.\n",
    "\n",
    "Pattern: [speakerID] [gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_list(audio_path, dirn):\n",
    "    r\"\"\"Count the number of recordings in Conversation and Interview directories, return a list of file names\n",
    "    Returns\n",
    "    -------\n",
    "    dir_list : list\n",
    "        a list of file names under the corresponding Conversation or Interview's audio directory\n",
    "    \"\"\"\n",
    "    dir_list = os.listdir(audio_path)\n",
    "    dir_list = [f for f in os.listdir(audio_path) if re.match(r'[^\\\\]+\\.flac', f)] # makes sure unwanted files like .DS_Store doesn't show up here! \n",
    "    print (\"there are total {} of files in {}\\n\".format(len(dir_list), audio_path))\n",
    "    if dirn == 'interview':\n",
    "        assert (len(dir_list) == 210), 'LDC2015S04/seame_d1/data/interview/audio should have 210 recordings, check if the directory is corrupted'\n",
    "    else:\n",
    "        assert (len(dir_list) == 87), 'LDC2015S04/seame_d2/data/conversation/audio should have 87 recordings, check if the directory is corrupted'\n",
    "    return dir_list\n",
    "\n",
    "def speaker_re_counts(dir_list):\n",
    "    r\"\"\"Create a dictionary mapping of prefix to the number of recordings under this prefix. \n",
    "    Returns\n",
    "    -------\n",
    "    id_dic : collections.defaultdict\n",
    "        a dictionary with key as recording prefix (tentative speaker id) and number of files associated with this prefix\n",
    "        e.g. (interview) 'NI52MBQ': 2\n",
    "        e.g. (conversation) '37NC45MBP': 1\n",
    "    \"\"\"\n",
    "    id_dic = defaultdict(int)\n",
    "    for file in dir_list:\n",
    "        id_dic[re.split('_', file)[0]] += 1\n",
    "    return id_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are total 210 of files in /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/LDC2015S04/seame_d2/data/interview/audio\n",
      "\n",
      "there are total 87 of files in /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/LDC2015S04/seame_d1/data/conversation/audio\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_path_i = parent_path + '/LDC2015S04/seame_d2/data/interview/audio'\n",
    "audio_path_c = parent_path + '/LDC2015S04/seame_d1/data/conversation/audio'\n",
    "\n",
    "dir_list_i = get_file_list(audio_path_i, 'interview')\n",
    "dir_list_c = get_file_list(audio_path_c, 'conversation')\n",
    "\n",
    "id_dic_i = speaker_re_counts(dir_list_i)\n",
    "id_dic_c = speaker_re_counts(dir_list_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def count_files(audio_path):\n",
    "#     dir_list = os.listdir(audio_path)[1:]\n",
    "#     print (\"there are total {} of files in {}\\n\".format(len(dir_list), audio_path))\n",
    "#     return dir_list\n",
    "# audio_path_i = parent_path + '/LDC2015S04/seame_d2/data/interview/audio'\n",
    "# audio_path_c = parent_path + '/LDC2015S04/seame_d1/data/conversation/audio'\n",
    "# dir_list_i = count_files(audio_path_i)\n",
    "# dir_list_c = count_files(audio_path_c)\n",
    "\n",
    "\n",
    "# def speaker_re_counts(dir_list):\n",
    "#     id_dic = defaultdict(int)\n",
    "#     for file in dir_list:\n",
    "#         id_dic[re.split('_', file)[0]] += 1\n",
    "#     print ('there are {} unique prefix sets'.format(len(id_dic)))\n",
    "#     return id_dic\n",
    "# id_dic_i = speaker_re_counts(dir_list_i)\n",
    "# id_dic_c = speaker_re_counts(dir_list_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_short_ids_i = ['01MA', '03FA','08MA', '29FA','29MB','42FB','44MB','45FB','67MB','55FB']\n",
    "# test_short_ids_c = ['01NC01FB', '01NC02FB','06NC11MA', '06NC12MA']\n",
    "\n",
    "# def train_test_split(id_dic, test_short_ids):\n",
    "#     train_ids = []\n",
    "#     test_ids = []\n",
    "#     for key in id_dic:\n",
    "#         if key[2:-1] in test_short_ids or key[:-1] in test_short_ids:\n",
    "#             test_ids.append(key)\n",
    "#         else: \n",
    "#             train_ids.append(key)\n",
    "#     print ('there are {} speaker ids in the training set'.format(len(train_ids)))\n",
    "#     print ('there are {} speaker ids in the testing set\\n'.format(len(test_ids)))\n",
    "#     return train_ids, test_ids\n",
    "# train_ids_i, test_ids_i = train_test_split(id_dic_i, test_short_ids_i)\n",
    "# train_ids_c, test_ids_c = train_test_split(id_dic_c, test_short_ids_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(id_dic, test_short_ids, dirn):\n",
    "    r\"\"\"generate a list of speaker id that should be the train or test set \n",
    "    Returns\n",
    "    -------\n",
    "    train_ids, test_ids : list, list\n",
    "        a list of ids that belong to train or test set \n",
    "        e.g. (interview train) 'NI52MBQ' (interview test) 'NI55FBP'\n",
    "        e.g. (conversation train) '37NC45MBP' (interview test) '01NC02FBY'\n",
    "    \"\"\"\n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "    for key in id_dic:\n",
    "        if key[2:-1] in test_short_ids or key[:-1] in test_short_ids:\n",
    "            test_ids.append(key)\n",
    "        else: \n",
    "            train_ids.append(key)\n",
    "    print ('there are {} unprocessed speaker ids in the training set'.format(len(train_ids)))\n",
    "    print ('there are {} unprocessed speaker ids in the testing set\\n'.format(len(test_ids)))\n",
    "    \n",
    "    if dirn == \"interview\":\n",
    "        assert (len(train_ids) == 85 and len(test_ids) == 10), \"For interview, there should be 85 speakers be moved to the training set, 10 speakers in test set\"\n",
    "    else:\n",
    "        assert (len(train_ids) == 75 and len(test_ids) == 4), \"For conversation, there should be 75 speakers be moved to the training set, 4 speakers in test set\"\n",
    "    \n",
    "    return train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 85 unprocessed speaker ids in the training set\n",
      "there are 10 unprocessed speaker ids in the testing set\n",
      "\n",
      "there are 75 unprocessed speaker ids in the training set\n",
      "there are 4 unprocessed speaker ids in the testing set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_short_ids_i = ['01MA', '03FA','08MA', '29FA','29MB','42FB','44MB','45FB','67MB','55FB']\n",
    "test_short_ids_c = ['01NC01FB', '01NC02FB','06NC11MA', '06NC12MA']\n",
    "\n",
    "train_ids_i, test_ids_i = train_test_split(id_dic_i, test_short_ids_i, \"interview\")\n",
    "train_ids_c, test_ids_c = train_test_split(id_dic_c, test_short_ids_c, \"conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NI44MBQ', 'NI45FBP', 'NI67MBQ', 'UI08MAZ', 'NI42FBQ']\n",
      "['UI20MAZ', 'UI17FAZ', 'NI22FBP', 'NI14MBP', 'NI37MBP']\n",
      "['06NC11MAX', '01NC02FBY', '01NC01FBX', '06NC12MAY']\n",
      "['41NC59MAX', '22NC44MBQ', '23NC35FBQ', '12NC23FBP', '15NC29FBP']\n"
     ]
    }
   ],
   "source": [
    "print (test_ids_i[:5])\n",
    "print (train_ids_i[:5])\n",
    "print (test_ids_c[:5])\n",
    "print (train_ids_c[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent path: /Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch\n"
     ]
    }
   ],
   "source": [
    "print (\"parent path: {}\".format(parent_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_spk2gender(id_list, dirt, dirn):\n",
    "    r\"\"\"create spk2gender file under data/train or data/test\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if dirt == \"train\":\n",
    "        directory = parent_path + \"/data/train/spk2gender\"\n",
    "    elif dirt == \"test\":\n",
    "        directory = parent_path + \"/data/test/spk2gender\"\n",
    "    with open(directory, 'a+') as outfile:\n",
    "        for speakerid in id_list:\n",
    "            if dirn == \"conversation\":\n",
    "                speakerid = speakerid[2:]\n",
    "                if speakerid == \"NC50XFB\": # this speaker is originally gender unknown, to prevent it from being filtered out by Kaldi, I assign it to be female\n",
    "                    gender = 'f'\n",
    "                else:\n",
    "                    gender = speakerid[4].lower()\n",
    "            else:\n",
    "                gender = speakerid[4].lower()\n",
    "            outfile.write(\"{} {}\\n\".format(speakerid, gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dir_clean_up(dir_path):\n",
    "    files = glob.glob(dir_path + '/*')\n",
    "    for f in files:\n",
    "        rmtree(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_clean_up(dir_path, fn):\n",
    "    to_be_removed = dir_path + \"/\" + fn\n",
    "    if os.path.isfile(to_be_removed):\n",
    "        os.remove(to_be_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up whatever is already in data/train or data/test\n",
    "file_clean_up(parent_path + \"/data/train\", \"spk2gender\")\n",
    "file_clean_up(parent_path + \"/data/test\", \"spk2gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 648\r\n",
      "-rw-r--r--  1 yehua  staff  196988 Apr 14 17:05 segments\r\n",
      "-rw-r--r--  1 yehua  staff  125578 Apr 14 17:05 utt2spk\r\n",
      "-rw-r--r--  1 yehua  staff    2748 Apr 14 23:20 wav.scp\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish generating spk2gender!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_spk2gender(train_ids_i, \"train\", \"interview\")\n",
    "generate_spk2gender(train_ids_c, \"train\", \"conversation\")\n",
    "generate_spk2gender(test_ids_i, \"test\", \"interview\")\n",
    "generate_spk2gender(test_ids_c, \"test\", \"conversation\")\n",
    "print (\"finish generating spk2gender!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 ../data/test/spk2gender\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -l ../data/test/spk2gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/train/spk2gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "grep x ../data/train/spk2gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # add interview speaker id to the train \n",
    "# directory = parent_path + \"/data/train/spk2gender\"\n",
    "# with open(directory, 'w') as outfile:\n",
    "#     for speakerid in train_ids_i:\n",
    "#         outfile.write(\"{} {}\\n\".format(speakerid,speakerid[4].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # add conversation speaker id to the train \n",
    "# directory = parent_path + \"/data/train/spk2gender\"\n",
    "# with open(directory, 'a+') as outfile:\n",
    "#     for speakerid in train_ids_c:\n",
    "#         outfile.write(\"{} {}\\n\".format(speakerid[2:],speakerid[6].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # add interview speaker id to the test \n",
    "# directory = parent_path + \"/data/test/spk2gender\"\n",
    "# with open(directory, 'w') as outfile:\n",
    "#     for speakerid in test_ids_i:\n",
    "#         outfile.write(\"{} {}\\n\".format(speakerid, speakerid[4].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # add conversation speaker id to the test \n",
    "# directory = parent_path + \"/data/test/spk2gender\"\n",
    "# with open(directory, 'a+') as outfile:\n",
    "#     for speakerid in test_ids_c:\n",
    "#         outfile.write(\"{} {}\\n\".format(speakerid[2:], speakerid[6].lower()))\n",
    "        \n",
    "# print (\"finish creating spk2gender in train and test set \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/test/spk2gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/train/spk2gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.) wav.scp \n",
    "This file connects every utterance (sentence said by one person during particular recording session) with an audio file related to this utterance. If you stick to my naming approach, 'utteranceID' is nothing more than 'speakerID' (speaker's folder name) glued with *.wav file name without '.wav' ending (look for examples below).\n",
    "\n",
    "Pattern: [recordingID] [full_path_to_audio_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 35456\r\n",
      "-rw-r--r--  1 yehua  staff  18149573 Mar 29 00:29 UI03FAZ_0101.flac\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../interview_audio/test/UI03FAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_wavscp(dir_list, id_list, dirt, dirn):\n",
    "    r\"\"\"generate wav.scp in data/train or data/test \n",
    "    the pattern for each line of the wav.scp file is <recording_id><full_path_to_audio_file> \n",
    "    because our audio is in flac, I need to tell Kaldi to convert it at some time\n",
    "    e.g. NC07FBX_040201 flac -c -d -s /codeswitch/audio/train/NC07FBX/NC07FBX_040201.flac |\n",
    "    Returns\n",
    "    -------\n",
    "    None \n",
    "    \"\"\"\n",
    "    if dirt == \"train\":\n",
    "        directory = parent_path + \"/data/train/wav.scp\"\n",
    "    else:\n",
    "        directory = parent_path + \"/data/test/wav.scp\"\n",
    "    with open(directory, 'a+') as outfile:\n",
    "        counter = 0\n",
    "        for file in dir_list:\n",
    "            speaker_id = re.split(\"_\", file)[0]\n",
    "            if dirt == \"train\" and dirn == \"conversation\":\n",
    "                if speaker_id in id_list:\n",
    "                    counter += 1\n",
    "                    if speaker_id[2:] in speaker_multiple: # rename e.g. 04NC07FBX_0201.flac to NC07FBX_040201.flac\n",
    "                        pre = re.split(\"_\",file)[0][:2]\n",
    "                        end = re.split(\"_\",file)[1].split(\".\")[0]\n",
    "                        newfile = re.split(\"_\",file)[0][2:] + '_' + pre + end + \".flac\"\n",
    "                        path = parent_path + \"/audio/train/\" + speaker_id[2:] + \"/\" + newfile\n",
    "                        recording_id = re.split(\"\\.\", newfile)[0]\n",
    "                        #print (\"this {} has multiple recordings, renaming them to {}\".format(speaker_id, newfile))\n",
    "                    else: \n",
    "                        path = parent_path + \"/audio/train/\" + speaker_id[2:] + \"/\" + file[2:]\n",
    "                        recording_id = re.split(\"\\.\", file)[0][2:]\n",
    "                    \n",
    "                    outfile.write(\"{} flac -c -d -s {} |\\n\".format(recording_id, path))\n",
    "\n",
    "            else: \n",
    "                if dirn == \"interview\" and speaker_id in id_list and dirt ==\"train\":\n",
    "                    counter += 1\n",
    "                    recording_id = re.split(\"\\.\", file)[0]\n",
    "                    path = parent_path + \"/audio/train/\" + speaker_id + \"/\" + file\n",
    "                    outfile.write(\"{} flac -c -d -s {} |\\n\".format(recording_id, path))\n",
    "                elif dirn == \"interview\" and speaker_id in id_list and dirt == \"test\":\n",
    "                    counter += 1\n",
    "                    recording_id = re.split(\"\\.\", file)[0]\n",
    "                    path = parent_path + \"/audio/test/\" + speaker_id + \"/\" + file\n",
    "                    outfile.write(\"{} flac -c -d -s {} |\\n\".format(recording_id, path))\n",
    "                elif dirn == \"conversation\" and speaker_id in id_list and dirt == \"test\":\n",
    "                    counter += 1\n",
    "                    recording_id = re.split(\"\\.\", file)[0][2:]\n",
    "                    path = parent_path + \"/audio/test/\" + speaker_id[2:] + \"/\" + file[2:]\n",
    "                    outfile.write(\"{} flac -c -d -s {} |\\n\".format(recording_id, path))\n",
    "                    \n",
    "        if dirt == \"train\" and dirn == \"conversation\":\n",
    "            assert(counter == 83), \"should write 83 lines from conversation to wav.scp (train)\"\n",
    "        elif dirt == \"test\" and dirn == \"conversation\":\n",
    "            assert(counter == 4), \"should write 4 lines from conversation to wav.scp (test)\"\n",
    "        elif dirt == \"train\" and dirn == \"interview\":\n",
    "             assert(counter == 194), \"should write 194 lines from interview to wav.scp (train)\"\n",
    "        else:\n",
    "            assert(counter == 16), \"should write 16 lines from interview to wav.scp (test)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up existing wav.scp \n",
    "file_clean_up(parent_path + \"/data/train\", \"wav.scp\")\n",
    "file_clean_up(parent_path + \"/data/test\", \"wav.scp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish generating wav.scp!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "speaker_multiple = ['NC50FBP', 'NC44MBQ', 'NC45MBP', 'NC05FAX', 'NC49FBQ', 'NC41MBP', 'NC07FBX', 'NC03FBX', 'NC04FBY', 'NC10MAY', 'NC37MBP', 'NC36MBQ', 'NC35FBQ', 'NC22MBQ', 'NC08FBY', 'NC48FBP', 'NC06FAY', 'NC43FBQ', 'NC09FAX']\n",
    "generate_wavscp(dir_list_c, train_ids_c, \"train\", \"conversation\")\n",
    "generate_wavscp(dir_list_i, train_ids_i, \"train\", \"interview\")\n",
    "generate_wavscp(dir_list_c, test_ids_c, \"test\", \"conversation\")\n",
    "generate_wavscp(dir_list_i, test_ids_i, \"test\", \"interview\")\n",
    "print (\"finish generating wav.scp!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish generating wav.scp\n"
     ]
    }
   ],
   "source": [
    "print (\"finish generating wav.scp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/train/wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/test/wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # add interview train into wav.scp \n",
    "\n",
    "# directory = parent_path + \"/data/train/wav.scp\"\n",
    "# with open(directory, 'w') as outfile:\n",
    "#     for file in dir_list_i:\n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in train_ids_i:\n",
    "#             path = parent_path + \"/audio/train/\" + speaker_id + \"/\" + file\n",
    "#             outfile.write(\"{} flac -c -d -s {} |\\n\".format(re.split(\"\\.\", file)[0], path))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to carefully re-name recordings in conversation, cause they don't have the speaker id as prefix. In their original naming convension, recordings from the same speaker will be identifies as different speaker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['08NC15MBP']\n"
     ]
    }
   ],
   "source": [
    "print(train_ids_c[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # add conversation train into wav.scp \n",
    "# speaker_multiple = ['NC50FBP', 'NC44MBQ', 'NC45MBP', 'NC05FAX', 'NC49FBQ', 'NC41MBP', 'NC07FBX', 'NC03FBX', 'NC04FBY', 'NC10MAY', 'NC37MBP', 'NC36MBQ', 'NC35FBQ', 'NC22MBQ', 'NC08FBY', 'NC48FBP', 'NC06FAY', 'NC43FBQ', 'NC09FAX']\n",
    "# directory = parent_path + \"/data/train/wav.scp\"\n",
    "# with open(directory, 'a+') as outfile:\n",
    "#     for file in dir_list_c:\n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in train_ids_c:\n",
    "#             if speaker_id[2:] in speaker_multiple:\n",
    "#                 pre = re.split(\"_\",file)[0][:2]\n",
    "#                 end = re.split(\"_\",file)[1].split(\".\")[0]\n",
    "#                 newfile = re.split(\"_\",file)[0][2:] + '_' + pre + end + \".flac\"\n",
    "#                 path = parent_path + \"/audio/train/\" + speaker_id[2:] + \"/\" + newfile\n",
    "#                 recording_id = re.split(\"\\.\", newfile)[0]\n",
    "#                 #print (\"this {} has multiple recordings, renaming them to {}\".format(speaker_id, newfile))\n",
    "#             else: \n",
    "#                 path = parent_path + \"/audio/train/\" + speaker_id[2:] + \"/\" + file[2:]\n",
    "#                 recording_id = re.split(\"\\.\", file)[0][2:]\n",
    "#             outfile.write(\"{} flac -c -d -s {} |\\n\".format(recording_id, path))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # add interview test into wav.scp \n",
    "\n",
    "# directory = parent_path + \"/data/test/wav.scp\"\n",
    "# with open(directory, 'w') as outfile:\n",
    "#     for file in dir_list_i:\n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in test_ids_i:\n",
    "#             path = parent_path + \"/audio/test/\" + speaker_id + \"/\" + file\n",
    "#             outfile.write(\"{} flac -c -d -s {} |\\n\".format(re.split(\"\\.\", file)[0], path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # add conversation test into wav.scp \n",
    "\n",
    "# directory = parent_path + \"/data/test/wav.scp\"\n",
    "# with open(directory, 'a+') as outfile:\n",
    "#     for file in dir_list_c:\n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in test_ids_c:\n",
    "#             path = parent_path + \"/audio/test/\" + speaker_id[2:] + \"/\" + file[2:]\n",
    "#             outfile.write(\"{} flac -c -d -s {} |\\n\".format(re.split(\"\\.\", file)[0][2:], path))\n",
    "# print (\"finish creating wav.scp in train and test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.) text \n",
    "This file contains every utterance matched with its text transcription.\n",
    "\n",
    "Pattern: [uterranceID] [text_transcription]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NI01MAX_0101.txt', 'NI02FAX_0101.txt']\n",
      "['01NC01FBX_0101.txt', '01NC02FBY_0101.txt']\n"
     ]
    }
   ],
   "source": [
    "# trans_path_i = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript\"\n",
    "# trans_list_i = os.listdir(trans_path_i)[1:]\n",
    "# trans_path_c = parent_path + \"/LDC2015S04/seame_d1/data/conversation/transcript\"\n",
    "# trans_list_c = os.listdir(trans_path_c)[1:]\n",
    "# print (trans_list_i[:2])\n",
    "# print (trans_list_c[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6952\r\n",
      "-rwxr-xr-x@ 1 yehua  staff   25240 Apr 11 17:15 NI01MAX_0101.txt*\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ../LDC2015S04/seame_d2/data/interview/transcript_filtered/ | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NI01MAX_0101.txt', 'NI02FAX_0101.txt']\n",
      "['01NC01FBX_0101.txt', '01NC02FBY_0101.txt']\n"
     ]
    }
   ],
   "source": [
    "trans_path_i = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript_filtered\"\n",
    "trans_list_i = [f for f in os.listdir(trans_path_i) if f.endswith(\".txt\")]\n",
    "trans_path_c = parent_path + \"/LDC2015S04/seame_d1/data/conversation/transcript_filtered\"\n",
    "trans_list_c = [f for f in os.listdir(trans_path_c) if f.endswith(\".txt\")]\n",
    "assert (len(trans_list_i) == 210), \"there should be 210 files in interview/transcript_filtered, check if the directory is corrupted\"\n",
    "assert (len(trans_list_c) == 87), \"there should be 87 files in conversation/transcript_filtered, check if the directory is corrupted\"\n",
    "print (trans_list_i[:2])\n",
    "print (trans_list_c[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_text(file_list, trans_path, id_list, dirt, dirn):\n",
    "    r\"\"\"generate text file\n",
    "    for each line the pattern is: <utterance_id><transcript>\n",
    "    e.g. NC03FBX_0101_0008400_0010710 就 那种 TYPICAL 的 偶 像 剧\n",
    "    \"\"\"\n",
    "    if dirt == \"test\":\n",
    "        directory = parent_path + \"/data/test/text\"\n",
    "    elif dirt == \"train\":\n",
    "        directory = parent_path + \"/data/train/text\"\n",
    "    counter = 0\n",
    "    with open(directory, 'a+') as outputfile:\n",
    "        for file in file_list:\n",
    "            speaker_id = re.split(\"_\", file)[0]\n",
    "            if speaker_id in id_list: \n",
    "                trans_file = trans_path + \"/\" + file\n",
    "                with open(trans_file, 'r') as inputfile: # only read file from transcript_filtered if the speaker is a match\n",
    "                    for line in inputfile:\n",
    "                        if dirn ==\"conversation\" and dirt == \"train\":\n",
    "                            if speaker_id[2:] in speaker_multiple:\n",
    "                                pre = re.split(\"_\",file)[0][:2] # e.g. 04\n",
    "                                end = re.split(\"_\",file)[1].split(\".\")[0] # e.g. 0201\n",
    "                                prefix = re.split(\"_\",file)[0][2:] + '_' + pre + end  #make 04NC08FBY_0201 -> NC08FBY_040201\n",
    "                            else:\n",
    "                                prefix = re.split(\" \", line)[0][2:] #make prefix 02NC03FBX_0101 -> NC03FBX_0101\n",
    "                            \n",
    "                        elif dirn ==\"conversation\" and dirt == \"test\":\n",
    "                            prefix = re.split(\" \", line)[0][2:]\n",
    "                        else:\n",
    "                            prefix = re.split(\" \", line)[0]\n",
    "                        text = \" \".join(re.split(\" \", line)[3:])\n",
    "                        first_frame = re.split(\" \", line)[1].zfill(7)\n",
    "                        second_frame = re.split(\" \", line)[2].zfill(7)\n",
    "                        utterance_id = prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "                        outputfile.write(\"{} {}\".format(utterance_id, text))\n",
    "                        counter += 1\n",
    "        print (\"write {} lines of {} text from {}\".format(counter, dirt, dirn))\n",
    "        if dirt == \"train\" and dirn == \"conversation\":\n",
    "            pass\n",
    "            #assert(counter == 13731), \"should write 13731 lines from conversation to text (train)\"\n",
    "        elif dirt == \"test\" and dirn == \"conversation\":\n",
    "            pass\n",
    "            #assert(counter == 485, \"should write 485 lines from conversation to text(test)\"\n",
    "        elif dirt == \"train\" and dirn == \"interview\":\n",
    "            pass\n",
    "            #assert(counter == 29505), \"should write 29505 lines from interview to text (train)\"\n",
    "        else:\n",
    "            pass\n",
    "            #assert(counter == 2909), \"should write 2909 lines from interview to wav.scp (test)\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean up existing wav.scp \n",
    "file_clean_up(parent_path + \"/data/train\", \"text\")\n",
    "file_clean_up(parent_path + \"/data/test\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write 13731 lines of train text from conversation\n",
      "finish creating text in data/train and data/test!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_text(trans_list_c, trans_path_c, train_ids_c, \"train\", \"conversation\")\n",
    "# write_text(trans_list_i, trans_path_i, train_ids_i, \"train\", \"interview\")\n",
    "# write_text(trans_list_c, trans_path_c, test_ids_c, \"test\", \"conversation\")\n",
    "# write_text(trans_list_i, trans_path_i, test_ids_i, \"test\", \"interview\")\n",
    "print (\"finish creating text in data/train and data/test!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/train/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43236 ../data/train/text\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -l ../data/train/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # create conversation text in train set \n",
    "# speaker_multiple = ['NC50FBP', 'NC44MBQ', 'NC45MBP', 'NC05FAX', 'NC49FBQ', 'NC41MBP', 'NC07FBX', 'NC03FBX', 'NC04FBY', 'NC10MAY', 'NC37MBP', 'NC36MBQ', 'NC35FBQ', 'NC22MBQ', 'NC08FBY', 'NC48FBP', 'NC06FAY', 'NC43FBQ', 'NC09FAX']\n",
    "# directory = parent_path + \"/data/train/text\"\n",
    "# counter = 0 \n",
    "# with open(directory, 'a+') as outputfile:\n",
    "#     for file in trans_list_c: \n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in train_ids_c:\n",
    "#             trans_file = trans_path_c + \"/\" + file\n",
    "#             with open(trans_file, 'r') as inputfile:\n",
    "#                 for line in inputfile:\n",
    "#                     if speaker_id[2:] in speaker_multiple:\n",
    "#                         pre = re.split(\"_\",file)[0][:2]\n",
    "#                         end = re.split(\"_\",file)[1].split(\".\")[0]\n",
    "#                         prefix = re.split(\"_\",file)[0][2:] + '_' + pre + end\n",
    "#                         #print (\"this speaker {} has multiple recordings, renaming it to {}\".format(speaker_id, prefix))\n",
    "\n",
    "#                     else: \n",
    "#                         prefix = re.split(\" \", line)[0][2:]\n",
    "#                     text = \" \".join(re.split(\" \", line)[3:])\n",
    "#                     first_frame = re.split(\" \", line)[1].zfill(7)\n",
    "#                     second_frame = re.split(\" \", line)[2].zfill(7)\n",
    "#                     utterance_id = prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "#                     outputfile.write(\"{} {}\".format(utterance_id, text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish create text in train and test set\n"
     ]
    }
   ],
   "source": [
    "# # create conversation text in test \n",
    "\n",
    "# directory = parent_path + \"/data/test/text\"\n",
    "# with open(directory, 'a+') as outputfile:\n",
    "#     for file in trans_list_c: \n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in test_ids_c:\n",
    "#             trans_file = trans_path_c + \"/\" + file\n",
    "#             with open(trans_file, 'r') as inputfile:\n",
    "#                 for line in inputfile:\n",
    "#                     text = \" \".join(re.split(\" \", line)[3:])\n",
    "#                     prefix = re.split(\" \", line)[0][2:]\n",
    "#                     first_frame = re.split(\" \", line)[1].zfill(7)\n",
    "#                     second_frame = re.split(\" \", line)[2].zfill(7)\n",
    "#                     utterance_id = prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "#                     outputfile.write(\"{} {}\".format(utterance_id, text))\n",
    "                    \n",
    "# print (\"finish create text in train and test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory = parent_path + \"/data/test/text\"\n",
    "# with open(directory, 'w') as outputfile:\n",
    "#     for file in trans_list_i: \n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in test_ids_i:\n",
    "#             trans_file = trans_path_i + \"/\" + file\n",
    "#             with open(trans_file, 'r') as inputfile:\n",
    "#                 for line in inputfile:\n",
    "#                     text = \" \".join(re.split(\" \", line)[3:])\n",
    "#                     prefix = re.split(\" \", line)[0]\n",
    "#                     first_frame = re.split(\" \", line)[1].zfill(7)\n",
    "#                     second_frame = re.split(\" \", line)[2].zfill(7)\n",
    "#                     utterance_id = prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "#                     outputfile.write(\"{} {}\".format(utterance_id, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory = parent_path + \"/data/train/text\"\n",
    "# with open(directory, 'w') as outputfile:\n",
    "#     for file in trans_list_i: \n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in train_ids_i:\n",
    "#             trans_file = trans_path_i + \"/\" + file\n",
    "#             with open(trans_file, 'r') as inputfile:\n",
    "#                 for line in inputfile:\n",
    "#                     text = \" \".join(re.split(\" \", line)[3:])\n",
    "#                     #text = re.split(\" \", line)[-1]\n",
    "#                     prefix = re.split(\" \", line)[0]\n",
    "#                     first_frame = re.split(\" \", line)[1].zfill(7)\n",
    "#                     second_frame = re.split(\" \", line)[2].zfill(7)\n",
    "#                     utterance_id = prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "                    outputfile.write(\"{} {}\".format(utterance_id, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/train/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06NC11MAX', '01NC02FBY', '01NC01FBX', '06NC12MAY']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/test/text_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.) utt2spk \n",
    "This file tells the ASR system which utterance belongs to particular speaker.\n",
    "\n",
    "Pattern: [uterranceID] [speakerID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_largest_frame(trans_list, trans_path):\n",
    "    largest_frame = -sys.maxsize\n",
    "    for file in trans_list:\n",
    "        file_path = trans_path + \"/\" + file\n",
    "        with open(file_path, 'r') as inputfile:\n",
    "            for line in inputfile:\n",
    "                second_frame = int(re.split(\" \", line)[2])\n",
    "                if second_frame > largest_frame:\n",
    "                    largest_frame = second_frame\n",
    "    return largest_frame\n",
    "\n",
    "def get_frame_size(frame1, frame2):\n",
    "    gframe = frame1\n",
    "    if gframe < frame2:\n",
    "        gframe = frame2\n",
    "    size = len(list(str(gframe)))\n",
    "    print (\"since {} is our largest frame, then we need to create string with {} digits to hold all frames\".format(gframe, size))\n",
    "    return size\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "since 7242490 is our largest frame, then we need to create string with 7 digits to hold all frames\n"
     ]
    }
   ],
   "source": [
    "frame1 = get_largest_frame(trans_list_c, trans_path_c)\n",
    "frame2 = get_largest_frame(trans_list_i, trans_path_i)\n",
    "size = get_frame_size(frame1, frame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 210 recording with transcript\n",
      "there are 210 recording in audio files\n",
      "match!\n",
      "largest_frame is 7004497\n"
     ]
    }
   ],
   "source": [
    "# #trans_path = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript/\"\n",
    "# import sys\n",
    "# largest_frame = -sys.maxsize\n",
    "# trans_list_i = os.listdir(trans_path_i)[1:]\n",
    "# print (\"there are {} recording with transcript\".format(len(trans_list_i)))\n",
    "# print (\"there are {} recording in audio files\".format(len(dir_list_i)))\n",
    "# print (\"match!\")\n",
    "\n",
    "# for file in trans_list_i:\n",
    "#     file_path = trans_path_i + \"/\" + file\n",
    "#     with open(file_path, 'r') as inputfile:\n",
    "#         for line in inputfile:\n",
    "#             second_frame = int(re.split(\" \", line)[2])\n",
    "#             if second_frame > largest_frame:\n",
    "#                 largest_frame = second_frame\n",
    "# print (\"largest_frame is {}\".format(largest_frame))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "largest_frame is 7242490\n",
      "since 7242490 is our largest frame, then we need to create string with 7 digits to hold all frames\n"
     ]
    }
   ],
   "source": [
    "# for file in trans_list_c:\n",
    "#     file_path = trans_path_c + \"/\" + file\n",
    "#     with open(file_path, 'r') as inputfile:\n",
    "#         for line in inputfile:\n",
    "#             second_frame = int(re.split(\" \", line)[2])\n",
    "#             if second_frame > largest_frame:\n",
    "#                 largest_frame = second_frame\n",
    "# print (\"largest_frame is {}\".format(largest_frame))  \n",
    "# print (\"since 7242490 is our largest frame, then we need to create string with 7 digits to hold all frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_utter_list(trans_list, trans_path, dirn):\n",
    "    r\"\"\"create a list of utterance_id\n",
    "    e.g. ['UI29FAZ_0104_0985128_0986293']\n",
    "    Returns\n",
    "    -------\n",
    "    utter_ids : list\n",
    "        A list of utterance_id\n",
    "    \"\"\"\n",
    "    utter_ids = []\n",
    "    for file in trans_list:\n",
    "        file_path = trans_path + \"/\" + file\n",
    "        with open(file_path, 'r') as inputfile:\n",
    "            for line in inputfile:\n",
    "                speaker_id = re.split(\"_\", line)[0]\n",
    "                if dirn == \"conversation\":\n",
    "                    if speaker_id[2:] in speaker_multiple:\n",
    "                        pre = re.split(\"_\",file)[0][:2]\n",
    "                        end = re.split(\"_\",file)[1].split(\".\")[0]\n",
    "                        prefix = re.split(\"_\",file)[0][2:] + '_' + pre + end\n",
    "                    else:\n",
    "                        prefix = re.split(\" \", line)[0][2:]\n",
    "                else:\n",
    "                    prefix = re.split(\" \", line)[0]\n",
    "                first_frame = re.split(\" \", line)[1].zfill(7)\n",
    "                second_frame = re.split(\" \", line)[2].zfill(7)\n",
    "                utterance_id =  prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "                utter_ids.append(utterance_id)\n",
    "    print (\"{} has {} utterance ids in total\".format(dirn, len(utter_ids)))\n",
    "    return utter_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interview has 32414 utterance ids in total\n",
      "conversation has 14216 utterance ids in total\n"
     ]
    }
   ],
   "source": [
    "utter_ids_i = gen_utter_list(trans_list_i, trans_path_i, \"interview\")\n",
    "utter_ids_c = gen_utter_list(trans_list_c, trans_path_c, \"conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 31658 new utterance ids\n"
     ]
    }
   ],
   "source": [
    "# # create utterance id for interview: recording id + start time + end time; for e.g. NI01MAX_0101_0001353_0003612\n",
    "# counter = 0\n",
    "# utter_ids_i = []\n",
    "# for file in trans_list_i:\n",
    "#     file_path = trans_path_i + \"/\" + file\n",
    "#     with open(file_path, 'r') as inputfile:\n",
    "#         for line in inputfile:\n",
    "#             speaker_id = re.split(\"_\", line)[0]\n",
    "#             prefix = re.split(\" \", line)[0]\n",
    "#             first_frame = re.split(\" \", line)[1].zfill(7)\n",
    "#             second_frame = re.split(\" \", line)[2].zfill(7)\n",
    "#             utterance_id =  prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "#             utter_ids_i.append(utterance_id)\n",
    "# print (\"there are {} new utterance ids\".format(len(utter_ids_i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UI29FAZ_0104_0985128_0986293'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_ids_i[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 14214 new utterance ids\n"
     ]
    }
   ],
   "source": [
    "# # create utterance id for conversation\n",
    "\n",
    "# counter = 0\n",
    "# utter_ids_c = []\n",
    "# for file in trans_list_c:\n",
    "#     file_path = trans_path_c + \"/\" + file\n",
    "#     with open(file_path, 'r') as inputfile:\n",
    "#         for line in inputfile:\n",
    "#             speaker_id = re.split(\"_\", line)[0]\n",
    "#             if speaker_id[2:] in speaker_multiple:\n",
    "#                 pre = re.split(\"_\",file)[0][:2]\n",
    "#                 end = re.split(\"_\",file)[1].split(\".\")[0]\n",
    "#                 prefix = re.split(\"_\",file)[0][2:] + '_' + pre + end\n",
    "#             else:\n",
    "#                 prefix = re.split(\" \", line)[0][2:]\n",
    "#             first_frame = re.split(\" \", line)[1].zfill(7)\n",
    "#             second_frame = re.split(\" \", line)[2].zfill(7)\n",
    "#             utterance_id =  prefix + \"_\" + first_frame + \"_\" + second_frame\n",
    "#             utter_ids_c.append(utterance_id)\n",
    "# print (\"there are {} new utterance ids\".format(len(utter_ids_c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NC41MBP_460101_3631302_3632862'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_ids_c[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample newly created utterance id ['NI01MAX_0101_0001353_0003612']\n"
     ]
    }
   ],
   "source": [
    "print(\"sample newly created utterance id {}\".format(utter_ids_i[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample newly created utterance id ['NC01FBX_0101_0086300_0088370']\n"
     ]
    }
   ],
   "source": [
    "print(\"sample newly created utterance id {}\".format(utter_ids_c[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ids_c_short = [ x[2:] for x in train_ids_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NC15MBP', 'NC42MBQ']\n"
     ]
    }
   ],
   "source": [
    "print (train_ids_c_short[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_utt2spk(id_list, utter_ids, dirt, dirn):\n",
    "    r\"\"\"create utt2spk file in data/train or data/test\n",
    "    For each line of utt2spk file the pattern is <utterance_id><speaker_id>\n",
    "    e.g. NC01FBX_0101_0086300_0088370 NC01FBX\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    if dirt == \"train\":\n",
    "        utt2spk_path = parent_path + \"/data/train/utt2spk\"\n",
    "    else:\n",
    "        utt2spk_path = parent_path + \"/data/test/utt2spk\"\n",
    "    if dirn == \"conversation\":\n",
    "        id_list = [x[2:] for x in id_list]\n",
    "    with open(utt2spk_path, 'a+') as outputfile:\n",
    "        for file in utter_ids:\n",
    "            speaker_id = re.split(\"_\", file)[0]\n",
    "            if speaker_id in id_list:\n",
    "                counter += 1\n",
    "                outputfile.write(\"{} {}\\n\".format(file, speaker_id))\n",
    "    print (\"write {} lines of utt2spk from {}\".format(counter, dirn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up any exisiting utt2spk\n",
    "file_clean_up(parent_path+\"/data/train\", 'utt2spk')\n",
    "file_clean_up(parent_path+\"/data/test\", 'utt2spk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write 13731 lines of utt2spk from conversation\n",
      "write 29505 lines of utt2spk from interview\n",
      "write 485 lines of utt2spk from conversation\n",
      "write 2909 lines of utt2spk from interview\n"
     ]
    }
   ],
   "source": [
    "create_utt2spk(train_ids_c, utter_ids_c, \"train\", \"conversation\")\n",
    "create_utt2spk(train_ids_i, utter_ids_i, \"train\", \"interview\")\n",
    "create_utt2spk(test_ids_c, utter_ids_c, \"test\", \"conversation\")\n",
    "create_utt2spk(test_ids_i, utter_ids_i, \"test\", \"interview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NC01FBX_0101_0086300_0088370', 'NC01FBX_0101_0165090_0167860']"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_ids_c[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['41NC59MAX', '22NC44MBQ']"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_c[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3331 in test/utt2spk\n"
     ]
    }
   ],
   "source": [
    "# test_ids_c_short = [x[2:] for x in test_ids_c]\n",
    "# utt2spk_path = parent_path + \"/data/test/utt2spk\"\n",
    "# counter = 0\n",
    "# with open(utt2spk_path, 'w') as outputfile:\n",
    "#     for file in utter_ids_i:\n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in test_ids_i:\n",
    "#             counter += 1\n",
    "#             outputfile.write(\"{} {}\\n\".format(file, speaker_id))\n",
    "#     for file in utter_ids_c:\n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in test_ids_c_short:\n",
    "#             counter += 1\n",
    "#             outputfile.write(\"{} {}\\n\".format(file, speaker_id))\n",
    "# print (\"there are {} in test/utt2spk\".format(counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 42541 in train/utt2spk\n"
     ]
    }
   ],
   "source": [
    "# utt2spk_path = parent_path + \"/data/train/utt2spk\"\n",
    "# counter = 0\n",
    "# with open(utt2spk_path, 'w') as outputfile:\n",
    "#     for file in utter_ids_i:\n",
    "#         speaker_id = re.split(\"_\", file)[0]\n",
    "#         if speaker_id in train_ids_i:\n",
    "#             counter += 1\n",
    "#             outputfile.write(\"{} {}\\n\".format(file, speaker_id))\n",
    "#     for file in utter_ids_c:\n",
    "#         speaker_id = re.split(\"_\",file)[0]\n",
    "#         if speaker_id in train_ids_c_short:\n",
    "#             counter += 1\n",
    "#             outputfile.write(\"{} {}\\n\".format(file, speaker_id))\n",
    "# print (\"there are {} in train/utt2spk\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06NC11MAX', '01NC02FBY', '01NC01FBX', '06NC12MAY']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/train/utt2spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/test/utt2spk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.) corpus.txt \n",
    "This file has a slightly different directory. In kaldi-trunk/egs/digits/data create another folder local. In kaldi/egs/code-switching/data/local create a file corpus.txt which should contain every single utterance transcription that can occur in your ASR system (in our case it will be 100 lines from 100 audio files).\n",
    "\n",
    "Pattern: [text_transcription]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/STARTRACK/deep-learning/code-switch/speech-to-text/codeswitch/LDC2015S04/seame_d1/data/conversation/transcript_filtered'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_path_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans_list_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NI01MAX_0101.txt', 'NI02FAX_0101.txt', 'NI03FBX_0101.txt']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_list_i[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01NC01FBX_0101.txt', '01NC02FBY_0101.txt', '02NC03FBX_0101.txt']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_list_c[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['41NC59MAX', '22NC44MBQ']"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_c[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UI20MAZ', 'UI17FAZ']"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_i[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_corpus(trans_list, trans_path, train_ids, dirn):\n",
    "    r\"\"\"write only transcript used in training to corpus.txt\n",
    "    each line of the corpus.txt has pattern <text_transcription>\n",
    "    e.g. 就是 那种 TYPICAL 偶 像 剧\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    temp_path = parent_path + \"/data/local\"\n",
    "    if not os.path.exists(temp_path):\n",
    "        os.makedirs(temp_path) \n",
    "    corpus_path = parent_path + \"/data/local/corpus.txt\"\n",
    "    with open(corpus_path, 'a+') as outputfile:\n",
    "        for file in trans_list:\n",
    "            speaker_id = re.split(\"_\",file)[0]\n",
    "            if speaker_id in train_ids: # only take in training set transcript to over information leakage\n",
    "                trans_file = trans_path + \"/\" + file\n",
    "                with open(trans_file, 'r') as inputfile:\n",
    "                    for line in inputfile:\n",
    "                        counter += 1\n",
    "                        outputfile.write(\" \".join(re.split(\" \", line)[3:]))\n",
    "    print (\"{} lines of transcript from {} is written to data/local/corpus.txt (training data only)\".format(counter, dirn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean up any exisiting utt2spk\n",
    "file_clean_up(parent_path+\"/data/local\", 'corpus.txt')\n",
    "file_clean_up(parent_path+\"/data/local\", 'corpus.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mlang\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13731 lines of transcript from conversation is written to data/local/corpus.txt (training data only)\n",
      "29505 lines of transcript from interview is written to data/local/corpus.txt (training data only)\n",
      "finish creating data/lang/corpus.txt!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_corpus(trans_list_c, trans_path_c, train_ids_c, \"conversation\")\n",
    "write_corpus(trans_list_i, trans_path_i, train_ids_i, \"interview\")\n",
    "print(\"finish creating data/lang/corpus.txt!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temp_path = parent_path + \"/data/local\"\n",
    "# if not os.path.exists(temp_path):\n",
    "#     os.makedirs(temp_path)\n",
    "    \n",
    "# corpus_path = parent_path + \"/data/local/corpus.txt\"\n",
    "# trans_path = parent_path + \"/LDC2015S04/seame_d2/data/interview/transcript_filtered\"\n",
    "# trans_list = os.listdir(trans_path)[1:]\n",
    "\n",
    "# with open(corpus_path, 'w') as outputfile:\n",
    "#     for file in trans_list: \n",
    "#             trans_file = trans_path + \"/\" + file\n",
    "#             with open(trans_file, 'r') as inputfile:\n",
    "#                 for line in inputfile:\n",
    "#                     #outputfile.write(line)\n",
    "#                     outputfile.write(\" \".join(re.split(\" \", line)[3:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temp_path = parent_path + \"/data/local\"\n",
    "# if not os.path.exists(temp_path):\n",
    "#     os.makedirs(temp_path)\n",
    "    \n",
    "# corpus_path = parent_path + \"/data/local/corpus.txt\"\n",
    "# trans_path = parent_path + \"/LDC2015S04/seame_d1/data/conversation/transcript_filtered\"\n",
    "# trans_list = os.listdir(trans_path)[1:]\n",
    "\n",
    "# with open(corpus_path, 'a+') as outputfile:\n",
    "#     for file in trans_list: \n",
    "#             trans_file = trans_path + \"/\" + file\n",
    "#             with open(trans_file, 'r') as inputfile:\n",
    "#                 for line in inputfile:\n",
    "#                     #outputfile.write(line)\n",
    "#                     outputfile.write(\" \".join(re.split(\" \", line)[3:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/local/corpus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) segments file  \n",
    "the format of the \"segments\" file is:  \n",
    "[utterance-id] [recoding-id] [segment-begin] [segment-end]   \n",
    "string.split(\"\\_\", 2) # split up to the second of occurences of _\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_segments(utter_ids, id_list, dirt, dirn):\n",
    "    r\"\"\"create segments file under data/train or data/test\n",
    "    for each line of this file has pattern <utterance_id><recording_id><segments_begin><segments_end>,\n",
    "    where <segments_begin> and <segments_end> are in second\n",
    "    e.g. NC01FBX_0101_0086300_0088370 NC01FBX_0101 86.3 88.37\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    if dirt == \"train\":\n",
    "        directory = parent_path + \"/data/train/segments\"\n",
    "    else:\n",
    "        directory = parent_path + \"/data/test/segments\"\n",
    "    if dirn == \"conversation\":\n",
    "        id_list = [i[2:] for i in id_list]\n",
    "    with open(directory, 'a+') as outputfile:\n",
    "        for utt in utter_ids:\n",
    "            speaker_id = re.split(\"_\", utt)[0]\n",
    "            if speaker_id in id_list:\n",
    "                recording_id = \"_\".join(utt.split(\"_\", 2)[:2])\n",
    "                segment_begin = str(int(re.split(\"_\", utt)[2])/1000.0)\n",
    "                segment_end = str(int(re.split(\"_\", utt)[3])/1000.0)\n",
    "                counter += 1\n",
    "                outputfile.write(\"{} {} {} {}\\n\".format(utt, recording_id, segment_begin, segment_end))\n",
    "    print (\"{} of lines of {} is written to segments in data/{}\".format(counter, dirn, dirt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NC01FBX_0101_0086300_0088370',\n",
       " 'NC01FBX_0101_0165090_0167860',\n",
       " 'NC01FBX_0101_0275720_0281420']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_ids_c[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean up any exisiting utt2spk\n",
    "file_clean_up(parent_path+\"/data/train\", 'segments')\n",
    "file_clean_up(parent_path+\"/data/test\", 'segments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spk2gender  text        utt2spk     wav.scp\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13731 of lines of conversation is written to segments in data/train\n",
      "29505 of lines of interview is written to segments in data/train\n",
      "485 of lines of conversation is written to segments in data/test\n",
      "2909 of lines of interview is written to segments in data/test\n"
     ]
    }
   ],
   "source": [
    "gen_segments(utter_ids_c, train_ids_c, \"train\", \"conversation\")\n",
    "gen_segments(utter_ids_i, train_ids_i, \"train\", \"interview\")\n",
    "gen_segments(utter_ids_c, test_ids_c, \"test\", \"conversation\")\n",
    "gen_segments(utter_ids_i, test_ids_i, \"test\", \"interview\")\n",
    "print (\"finish creating segments file!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # interview segments file for training set\n",
    "# directory = parent_path + \"/data/train/segments\"\n",
    "# counter = 0\n",
    "# with open(directory, 'w') as outputfile:\n",
    "#     for utt in utter_ids_i:\n",
    "#         speaker_id = re.split(\"_\", utt)[0]\n",
    "#         if speaker_id in train_ids_i:\n",
    "            \n",
    "#             recording_id = \"_\".join(utt.split(\"_\", 2)[:2])\n",
    "#             segment_begin = str(int(re.split(\"_\", utt)[2])/1000)\n",
    "#             segment_end = str(int(re.split(\"_\", utt)[3])/1000)\n",
    "#             outputfile.write(\"{} {} {} {}\\n\".format(utt, recording_id, segment_begin, segment_end))\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NC01FBX_0101_0086300_0088370', 'NC01FBX_0101_0165090_0167860']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_ids_c[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # conversation segments file for training set\n",
    "\n",
    "# directory = parent_path + \"/data/train/segments\"\n",
    "# counter = 0\n",
    "# with open(directory, 'a+') as outputfile:\n",
    "#     for utt in utter_ids_c:\n",
    "#         speaker_id = re.split(\"_\", utt)[0]\n",
    "#         if speaker_id in train_ids_c_short:\n",
    "            \n",
    "#             recording_id = \"_\".join(utt.split(\"_\", 2)[:2])\n",
    "#             segment_begin = str(int(re.split(\"_\", utt)[2])/1000)\n",
    "#             segment_end = str(int(re.split(\"_\", utt)[3])/1000)\n",
    "#             outputfile.write(\"{} {} {} {}\\n\".format(utt, recording_id, segment_begin, segment_end))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2846\n"
     ]
    }
   ],
   "source": [
    "# # interview segments file for training set\n",
    "# directory = parent_path + \"/data/test/segments\"\n",
    "# counter = 0 \n",
    "# with open(directory, 'w') as outputfile:\n",
    "#     for utt in utter_ids_i:\n",
    "#         speaker_id = re.split(\"_\", utt)[0]\n",
    "#         if speaker_id in test_ids_i:\n",
    "# #             if speaker_id == 'NI01MAX':\n",
    "# #                 #print (speaker_id)\n",
    "#             recording_id = \"_\".join(utt.split(\"_\", 2)[:2])\n",
    "#             segment_begin = str(int(re.split(\"_\", utt)[2])/1000)\n",
    "#             segment_end = str(int(re.split(\"_\", utt)[3])/1000)\n",
    "#             outputfile.write(\"{} {} {} {}\\n\".format(utt, recording_id, segment_begin, segment_end))\n",
    "#             counter += 1\n",
    "# print (counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485\n"
     ]
    }
   ],
   "source": [
    "# # conversation segments file for test set\n",
    "# directory = parent_path + \"/data/test/segments\"\n",
    "# counter = 0 \n",
    "# with open(directory, 'a+') as outputfile:\n",
    "#     for utt in utter_ids_c:\n",
    "#         speaker_id = re.split(\"_\", utt)[0]\n",
    "#         if speaker_id in test_ids_c_short:\n",
    "# #             if speaker_id == 'NI01MAX':\n",
    "# #                 #print (speaker_id)\n",
    "#             recording_id = \"_\".join(utt.split(\"_\", 2)[:2])\n",
    "#             segment_begin = str(int(re.split(\"_\", utt)[2])/1000)\n",
    "#             segment_end = str(int(re.split(\"_\", utt)[3])/1000)\n",
    "#             outputfile.write(\"{} {} {} {}\\n\".format(utt, recording_id, segment_begin, segment_end))\n",
    "#             counter += 1\n",
    "# print (counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less ../data/train/segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less ../data/test/segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NC01FBX_0101_0086300_0088370', 'NC01FBX_0101_0165090_0167860']"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_ids_c[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (☞ﾟ∀ﾟ)☞ acoustic data prep is succesfully finished!\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n (☞ﾟ∀ﾟ)☞ acoustic data prep is succesfully finished!\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
