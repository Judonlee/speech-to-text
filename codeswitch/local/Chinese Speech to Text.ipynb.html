{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /home/ubuntu/kaldi/egs/thchs30/s5\n",
    "wget http://www.openslr.org/resources/18/data_thchs30.tgz\n",
    "wget http://www.openslr.org/resources/18/test-noise.tgz\n",
    "wget http://www.openslr.org/resources/18/resource.tgz\n",
    "mkdir -p thchs30-openslr\n",
    "tar zxvf data_thchs30.tgz -C thchs30-openslr\n",
    "tar zxvf test-noise.tgz -C thchs30-openslr\n",
    "tar zxvf resource.tgz -C thchs30-openslr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above commands to download the dataset from http://www.openslr.org/18/ and extract them.\n",
    "You may need to use \"free -m\" to check your space availablility.\n",
    "\n",
    "THCHS30 is an open Chinese speech database published by Center for Speech and Language Technology (CSLT) at Tsinghua University.\n",
    "\n",
    "The folder data_thchs30 is 7.5GB unzip. Because of the space limitation, I only extract 1/4 datasets for the model training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to modify s5/cmd.sh file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export train_cmd=run.pl\n",
    "export decode_cmd=run.pl\n",
    "export mkgraph_cmd=run.pl\n",
    "export cuda_cmd=run.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is better to run s5/run.sh file step by step.\n",
    "\n",
    "Here, I only use tri1 model as an example. Modify the s5/sun.sh as follows.\n",
    "\n",
    "Note: We can also use \"<<!EOF!   !EOF!\" to comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    ". ./cmd.sh\n",
    ". ./path.sh\n",
    "\n",
    "H=`pwd`  #exp home\n",
    "n=8      #parallel jobs\n",
    "\n",
    "#corpus and trans directory\n",
    "thchs=/home/ubuntu/kaldi/egs/thchs30/s5/thchs30-openslr\n",
    "\n",
    "#data preparation \n",
    "#generate text, wav.scp, utt2pk, spk2utt\n",
    "local/thchs-30_data_prep.sh $H $thchs/data_thchs30 || exit 1;\n",
    "\n",
    "#produce MFCC features \n",
    "rm -rf data/mfcc && mkdir -p data/mfcc &&  cp -R data/{train,dev,test,test_phone} data/mfcc || exit 1;\n",
    "for x in train dev test; do\n",
    "   #make  mfcc \n",
    "   steps/make_mfcc.sh --nj $n --cmd \"$train_cmd\" data/mfcc/$x exp/make_mfcc/$x mfcc/$x || exit 1;\n",
    "   #compute cmvn\n",
    "   steps/compute_cmvn_stats.sh data/mfcc/$x exp/mfcc_cmvn/$x mfcc/$x || exit 1;\n",
    "done\n",
    "#copy feats and cmvn to test.ph, avoid duplicated mfcc & cmvn \n",
    "cp data/mfcc/test/feats.scp data/mfcc/test_phone && cp data/mfcc/test/cmvn.scp data/mfcc/test_phone || exit 1;\n",
    "\n",
    "\n",
    "#prepare language stuff\n",
    "#build a large lexicon that invovles words in both the training and decoding. \n",
    "(\n",
    "  echo \"make word graph ...\"\n",
    "  cd $H; mkdir -p data/{dict,lang,graph} && \\\n",
    "  cp $thchs/resource/dict/{extra_questions.txt,nonsilence_phones.txt,optional_silence.txt,silence_phones.txt} data/dict && \\\n",
    "  cat $thchs/resource/dict/lexicon.txt $thchs/data_thchs30/lm_word/lexicon.txt | \\\n",
    "  \tgrep -v '<s>' | grep -v '</s>' | sort -u > data/dict/lexicon.txt || exit 1;\n",
    "  utils/prepare_lang.sh --position_dependent_phones false data/dict \"<SPOKEN_NOISE>\" data/local/lang data/lang || exit 1;\n",
    "  gzip -c $thchs/data_thchs30/lm_word/word.3gram.lm > data/graph/word.3gram.lm.gz || exit 1;\n",
    "  utils/format_lm.sh data/lang data/graph/word.3gram.lm.gz $thchs/data_thchs30/lm_word/lexicon.txt data/graph/lang || exit 1;\n",
    ")\n",
    "\n",
    "#make_phone_graph\n",
    "(\n",
    "  echo \"make phone graph ...\"\n",
    "  cd $H; mkdir -p data/{dict_phone,graph_phone,lang_phone} && \\\n",
    "  cp $thchs/resource/dict/{extra_questions.txt,nonsilence_phones.txt,optional_silence.txt,silence_phones.txt} data/dict_phone  && \\\n",
    "  cat $thchs/data_thchs30/lm_phone/lexicon.txt | grep -v '<eps>' | sort -u > data/dict_phone/lexicon.txt  && \\\n",
    "  echo \"<SPOKEN_NOISE> sil \" >> data/dict_phone/lexicon.txt  || exit 1;\n",
    "  utils/prepare_lang.sh --position_dependent_phones false data/dict_phone \"<SPOKEN_NOISE>\" data/local/lang_phone data/lang_phone || exit 1;\n",
    "  gzip -c $thchs/data_thchs30/lm_phone/phone.3gram.lm > data/graph_phone/phone.3gram.lm.gz  || exit 1;\n",
    "  utils/format_lm.sh data/lang_phone data/graph_phone/phone.3gram.lm.gz $thchs/data_thchs30/lm_phone/lexicon.txt \\\n",
    "    data/graph_phone/lang  || exit 1;\n",
    ")\n",
    "\n",
    "#triphone\n",
    "steps/train_deltas.sh --boost-silence 1.25 --cmd \"$train_cmd\" 2000 10000 data/mfcc/train data/lang exp/mono_ali exp/tri1 || exit 1;\n",
    "#test tri1 model\n",
    "local/thchs-30_decode.sh --nj $n \"steps/decode.sh\" exp/tri1 data/mfcc &\n",
    "\n",
    "#triphone_ali\n",
    "steps/align_si.sh --nj $n --cmd \"$train_cmd\" data/mfcc/train data/lang exp/tri1 exp/tri1_ali || exit 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to exp/tri1/decode_test_word/scoring_kaldi, where you can find the error rate at \"best_wer\".\n",
    "\n",
    "We need to keep three important files:\n",
    "\n",
    "1)Model: exp/tri1/final.ml\n",
    "\n",
    "2)Dictionary: exp/tri1/graph_word/words.txt\n",
    "\n",
    "3)Finite automation: exp/tri1/graph_word/HCLG.fst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step, make sure to install portaudio successfully.\n",
    "\n",
    "Check if kaldi/src/onlinebin/online-wav-gmm-decode-faster kaldi/src/onlinebin/online-gmm-decode-faster has existed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /home/ubuntu/kaldi/tools\n",
    "./install_portaudio.sh\n",
    "cd /home/ubuntu/kaldi/src\n",
    "make ext -j 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy egs/voxforge/online_demo to kaldi/egs/thchs30\n",
    "cp -r /home/ubuntu/kaldi/egs/voxforge/online_demo /home/ubuntu/kaldi/egs/thchs30/\n",
    "cd /home/ubuntu/kaldi/egs/thchs30/online_demo\n",
    "mkdir online-data\n",
    "cd online-data\n",
    "mkdir audio && mkdir models\n",
    "cd models\n",
    "mkdir mono\n",
    "cp /home/ubuntu/kaldi/egs/thchs30/s5/exp/mono/final.mdl /home/ubuntu/kaldi/egs/thchs30/online_demo/online-data/models/mono/\n",
    "cp /home/ubuntu/kaldi/egs/thchs30/s5/exp/mono/40.mdl /home/ubuntu/kaldi/egs/thchs30/online_demo/online-data/models/mono\n",
    "cp /home/ubuntu/kaldi/egs/thchs30/s5/exp/mono/graph_word/words.txt /home/ubuntu/kaldi/egs/thchs30/online_demo/online-data/models/mono\n",
    "mv -v /home/ubuntu/kaldi/egs/thchs30/s5/exp/mono/graph_word/HCLG.fst /home/ubuntu/kaldi/egs/thchs30/online_demo/online-data/models/mono\n",
    "cp /home/ubuntu/kaldi/egs/thchs30/s5/thchs30-openslr/data_thchs30/test/D6_750.wav /home/ubuntu/kaldi/egs/thchs30/online_demo/online-data/audio\n",
    "cp /home/ubuntu/kaldi/egs/thchs30/s5/thchs30-openslr/data_thchs30/test/D6_750.wav.trn /home/ubuntu/kaldi/egs/thchs30/online_demo/online-data/audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify egs/voxforge/online_demo/run.sh as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Copyright 2012 Vassil Panayotov\n",
    "# Apache 2.0\n",
    "\n",
    "# Note: you have to do 'make ext' in ../../../src/ before running this.\n",
    "\n",
    "# Set the paths to the binaries and scripts needed\n",
    "KALDI_ROOT=`pwd`/../../..\n",
    "export PATH=$PWD/../s5/utils/:$KALDI_ROOT/src/onlinebin:$KALDI_ROOT/src/bin:$PATH\n",
    "\n",
    "data_file=\"online-data\"\n",
    "data_url=\"http://sourceforge.net/projects/kaldi/files/online-data.tar.bz2\"\n",
    "\n",
    "# Change this to \"tri2a\" if you like to test using a ML-trained model\n",
    "ac_model_type=mono\n",
    "\n",
    "# Alignments and decoding results are saved in this directory(simulated decoding only)\n",
    "decode_dir=\"./work\"\n",
    "\n",
    "# Change this to \"live\" either here or using command line switch like:\n",
    "# --test-mode live\n",
    "test_mode=\"simulated\"\n",
    "\n",
    ". parse_options.sh\n",
    "\n",
    "ac_model=${data_file}/models/$ac_model_type\n",
    "trans_matrix=\"\"\n",
    "audio=${data_file}/audio\n",
    "\n",
    "if [ ! -d $ac_model ]; then\n",
    "    echo \"Extracting the models and data ...\"\n",
    "    tar xf ${data_file}.tar.bz2\n",
    "fi\n",
    "\n",
    "if [ -s $ac_model/matrix ]; then\n",
    "    trans_matrix=$ac_model/matrix\n",
    "fi\n",
    "\n",
    "case $test_mode in\n",
    "    live)\n",
    "        echo\n",
    "        echo -e \"  LIVE DEMO MODE - you can use a microphone and say something\\n\"\n",
    "        echo \"  The (bigram) language model used to build the decoding graph was\"\n",
    "        echo \"  estimated on an audio book's text. The text in question is\"\n",
    "        echo \"  \\\"King Solomon's Mines\\\" (http://www.gutenberg.org/ebooks/2166).\"\n",
    "        echo \"  You may want to read some sentences from this book first ...\"\n",
    "        echo\n",
    "        online-gmm-decode-faster --rt-min=0.5 --rt-max=0.7 --max-active=4000 \\\n",
    "           --beam=12.0 --acoustic-scale=0.0769 $ac_model/final.mdl $ac_model/HCLG.fst \\\n",
    "           $ac_model/words.txt '1:2:3:4:5' $trans_matrix;;\n",
    "\n",
    "    simulated)\n",
    "        echo\n",
    "        echo -e \"  SIMULATED ONLINE DECODING - pre-recorded audio is used\\n\"\n",
    "        echo \"  The (bigram) language model used to build the decoding graph was\"\n",
    "        echo \"  estimated on an audio book's text. The text in question is\"\n",
    "        echo \"  \\\"King Solomon's Mines\\\" (http://www.gutenberg.org/ebooks/2166).\"\n",
    "        echo \"  The audio chunks to be decoded were taken from the audio book read\"\n",
    "        echo \"  by John Nicholson(http://librivox.org/king-solomons-mines-by-haggard/)\"\n",
    "        echo\n",
    "        echo \"  NOTE: Using utterances from the book, on which the LM was estimated\"\n",
    "        echo \"        is considered to be \\\"cheating\\\" and we are doing this only for\"\n",
    "        echo \"        the purposes of the demo.\"\n",
    "        echo\n",
    "        echo \"  You can type \\\"./run.sh --test-mode live\\\" to try it using your\"\n",
    "        echo \"  own voice!\"\n",
    "        echo\n",
    "        mkdir -p $decode_dir\n",
    "        # make an input .scp file\n",
    "        > $decode_dir/input.scp\n",
    "        for f in $audio/*.wav; do\n",
    "            bf=`basename $f`\n",
    "            bf=${bf%.wav}\n",
    "            echo $bf $f >> $decode_dir/input.scp\n",
    "        done\n",
    "        online-wav-gmm-decode-faster --verbose=1 --rt-min=0.8 --rt-max=0.85\\\n",
    "            --max-active=4000 --beam=12.0 --acoustic-scale=0.0769 \\\n",
    "            scp:$decode_dir/input.scp $ac_model/final.mdl $ac_model/HCLG.fst \\\n",
    "            $ac_model/words.txt '1:2:3:4:5' ark,t:$decode_dir/trans.txt \\\n",
    "            ark,t:$decode_dir/ali.txt $trans_matrix;;\n",
    "\n",
    "    *)\n",
    "        echo \"Invalid test mode! Should be either \\\"live\\\" or \\\"simulated\\\"!\";\n",
    "        exit 1;;\n",
    "esac\n",
    "\n",
    "# Estimate the error rate for the simulated decoding\n",
    "if [ $test_mode == \"simulated\" ]; then\n",
    "    # Convert the reference transcripts from symbols to word IDs\n",
    "    sym2int.pl -f 2- $ac_model/words.txt < $audio/trans.txt > $decode_dir/ref.txt\n",
    "\n",
    "    # Compact the hypotheses belonging to the same test utterance\n",
    "    cat $decode_dir/trans.txt |\\\n",
    "        sed -e 's/^\\(test[0-9]\\+\\)\\([^ ]\\+\\)\\(.*\\)/\\1 \\3/' |\\\n",
    "        gawk '{key=$1; $1=\"\"; arr[key]=arr[key] \" \" $0; } END { for (k in arr) { print k \" \" arr[k]} }' > $decode_dir/hyp.txt\n",
    "\n",
    "   # Finally compute WER\n",
    "   compute-wer --mode=present ark,t:$decode_dir/ref.txt ark,t:$decode_dir/hyp.txt\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /home/ubuntu/kaldi/egs/thchs30/online_demo\n",
    "./run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "online-wav-gmm-decode-faster --verbose=1 --rt-min=0.8 --rt-max=0.85 --max-active=4000 --beam=12.0 --acoustic-scale=0.0769 scp:./work/input.scp online-data/models/mono/final.mdl online-data/models/mono/HCLG.fst online-data/models/mono/words.txt 1:2:3:4:5 ark,t:./work/trans.txt ark,t:./work/ali.txt \n",
    "\n",
    "File: D6_750\n",
    "\n",
    "东北 军队 院校 爱国 将领 把 泰山 你 不 常见 五 艘 弊 案 侦 结 对等 学分 起草 的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "./run.sh --test-mode live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above command supports decoding input speech via microphone.\n",
    "\n",
    "However, error occurs: PortAudio failed to open the default stream.\n",
    "\n",
    "We may need more configuration on PortAudio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
